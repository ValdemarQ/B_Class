{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch tutorials.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZSMXhY5wpml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCx4jrUlybCL",
        "colab_type": "text"
      },
      "source": [
        "# Tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9UxNhofwrZM",
        "colab_type": "code",
        "outputId": "4f92668b-43df-4391-8532-2bcd5891236d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "#creating empty tensor\n",
        "x = torch.empty(2,2,3)\n",
        "x"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[5.2418e-36, 0.0000e+00, 0.0000e+00],\n",
              "         [0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
              "\n",
              "        [[0.0000e+00, 0.0000e+00, 2.8026e-45],\n",
              "         [0.0000e+00, 1.1210e-44, 0.0000e+00]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOEerLZDwta6",
        "colab_type": "code",
        "outputId": "b6d9cbfd-6339-42e0-8d59-101454914654",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#creating random tensor\n",
        "x = torch.rand(3)\n",
        "x"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.1584, 0.5163, 0.5537])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_KRWBHCwuOK",
        "colab_type": "code",
        "outputId": "ce014773-2fe5-4085-c97d-0069ed3d082d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#create torch with 0 or 1s\n",
        "x = torch.ones(2,3)\n",
        "x.dtype"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZydLFMAxnJ0",
        "colab_type": "code",
        "outputId": "19436df3-a9d4-4996-bec2-048778b089d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#create your own tensor as you want\n",
        "x = torch.tensor([2.5,0.1])\n",
        "x"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2.5000, 0.1000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DTs6wa3xKAU",
        "colab_type": "code",
        "outputId": "b159caf7-c2b5-4df8-94ee-866172df9e6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#create torch with different types\n",
        "x = torch.ones(2,3, dtype=torch.int) #doubles, float16 etc...\n",
        "x.dtype"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.int32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSI2Z7i4xWpK",
        "colab_type": "code",
        "outputId": "a1a3133e-8193-4595-bcac-55323b9f5314",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#check size of a tensor\n",
        "x.size()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPQ7zlYNyf_x",
        "colab_type": "text"
      },
      "source": [
        "# Basic tensor operations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXyLXmMuyhXb",
        "colab_type": "code",
        "outputId": "d15acd83-1c42-44b5-df6d-287c7623816c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "x = torch.rand(2,2)\n",
        "y = torch.rand(2,2)\n",
        "print(x)\n",
        "print(y)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.3365, 0.7350],\n",
            "        [0.2881, 0.8531]])\n",
            "tensor([[0.9568, 0.3192],\n",
            "        [0.1838, 0.3625]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6XQY7Nnylpq",
        "colab_type": "code",
        "outputId": "28d75823-50a9-488e-e214-e29964e1469b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "z = x + y #element wise addition\n",
        "z"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.2933, 1.0541],\n",
              "        [0.4719, 1.2156]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUNiqBzzypCS",
        "colab_type": "code",
        "outputId": "30a69cda-0cdd-43bc-a669-86933af16df4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "z = torch.add(x,y) #same as top version\n",
        "z"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.2933, 1.0541],\n",
              "        [0.4719, 1.2156]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Gcb8wQvyyqD",
        "colab_type": "code",
        "outputId": "9dec59ce-db28-4343-f308-2db94a570576",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "y.add_(x) #_ makes inplace operation - same addition replacing y value x + y\n",
        "y"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.2933, 1.0541],\n",
              "        [0.4719, 1.2156]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cwvGGaqzMpL",
        "colab_type": "code",
        "outputId": "0e097695-e11e-4c09-e064-41a3440e3376",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "z = x - y #or z = torch.sub(x,y)\n",
        "z"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.9568, -0.3192],\n",
              "        [-0.1838, -0.3625]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nu7KOS2EzOv6",
        "colab_type": "code",
        "outputId": "c757d92f-9157-4081-b951-a2ddf2afc269",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "z = x * y #or z = torch.mul(x,y)\n",
        "z"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4352, 0.7748],\n",
              "        [0.1359, 1.0370]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1eDUFmx4ofc",
        "colab_type": "text"
      },
      "source": [
        "# Slicing example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pTLrdu2zWxD",
        "colab_type": "code",
        "outputId": "ad6fc0c5-cd32-4f3a-98bd-a22a778a2546",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "x = torch.rand(5,3)\n",
        "x"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3145, 0.9064, 0.4650],\n",
              "        [0.0687, 0.7879, 0.7986],\n",
              "        [0.0280, 0.2310, 0.5879],\n",
              "        [0.4856, 0.4464, 0.3242],\n",
              "        [0.3877, 0.9108, 0.4046]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkXch2tYzwHV",
        "colab_type": "code",
        "outputId": "9f00f5fc-dce6-40c8-9659-07a74f052a30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x[:,0] #1st row of the first column"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.3145, 0.0687, 0.0280, 0.4856, 0.3877])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-B9Ix3vAzdcK",
        "colab_type": "code",
        "outputId": "ead4da1f-695f-4bd2-80bd-06c11a45ca22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x[1,:] #2nd row of all columns"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0687, 0.7879, 0.7986])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9faRWIEGzscr",
        "colab_type": "code",
        "outputId": "e4d5f274-30a7-4fdc-f16e-28d2e7ae2a94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x[1,1] #getting exact value"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.7879)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSaptIZM4uQ0",
        "colab_type": "text"
      },
      "source": [
        "# Reshaping tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcZ4CyS04Xg0",
        "colab_type": "code",
        "outputId": "e18a4640-a7e5-4b3c-8f82-d1390e071b58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "x = torch.rand(4,4)\n",
        "x"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2737, 0.3189, 0.6497, 0.6191],\n",
              "        [0.6617, 0.8573, 0.5016, 0.5373],\n",
              "        [0.4988, 0.4935, 0.3746, 0.2720],\n",
              "        [0.2299, 0.9461, 0.4888, 0.3515]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70pKLAqv4ei6",
        "colab_type": "code",
        "outputId": "e31fd0db-3b94-4502-f075-f5fdd9263798",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "y = x.view(16) #making 1d vector from X, number of elements must be the same\n",
        "y"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2737, 0.3189, 0.6497, 0.6191, 0.6617, 0.8573, 0.5016, 0.5373, 0.4988,\n",
              "        0.4935, 0.3746, 0.2720, 0.2299, 0.9461, 0.4888, 0.3515])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKXLRCQ-4gw3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converting from numpy to pytorch tensore"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01lB9BiV40oK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-nXzaoi41gB",
        "colab_type": "code",
        "outputId": "01f0178e-d592-4bb4-e8c9-3b7289ce4fee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "a = torch.ones(5)\n",
        "a"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1., 1., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nSc6j_v45Ma",
        "colab_type": "code",
        "outputId": "a1ce9ae0-4d9b-4ca8-c5de-a797f7e3133a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "b = a.numpy() #turninig a into numpy array\n",
        "print(b)\n",
        "print(type(b))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 1. 1. 1. 1.]\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meT04kZm49K6",
        "colab_type": "code",
        "outputId": "1ca5a3fb-121d-4dba-aa10-3b00ab51d9e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "a.add_(1)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2., 2., 2., 2., 2.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLIjsESI5QqC",
        "colab_type": "code",
        "outputId": "e8b652bc-9b4f-4614-f683-837b05e99e6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(b) #B has also changed, because they both share same memory on cpu."
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2. 2. 2. 2. 2.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtLtWoPZ6o09",
        "colab_type": "text"
      },
      "source": [
        "### pytorch will require calculate gradient for this\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWCsTlY65SMa",
        "colab_type": "code",
        "outputId": "3d25c1b1-6ac6-48ee-ed03-4b28e78633cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x = torch.ones(5,requires_grad=True) \n",
        "x"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1., 1., 1.], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4H4winR6v4U",
        "colab_type": "text"
      },
      "source": [
        "# Autograd package - Pytorch\n",
        "So how to calculate gradients, and how to use packaged?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWdPrmrt6zmJ",
        "colab_type": "code",
        "outputId": "90949e78-3c92-4a0d-87c5-ed2d04659d2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x = torch.randn(3, requires_grad=True) #we need to specific requires_grad=True\n",
        "x #we see pytorch tracks it"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.8565,  0.3700, -1.4974], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mX_rEFcR641h",
        "colab_type": "code",
        "outputId": "29c0b208-b895-4489-c31d-daddf4ac929e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y = x + 2 #python will create fuction for use, which will later calculate gradient for us\n",
        "y"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.1435, 2.3700, 0.5026], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vExaypog7Q1W",
        "colab_type": "code",
        "outputId": "7e96bf75-ee68-4a90-eeaf-12dd05e1149f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        " z= y*y*2\n",
        " z = z.mean() # if z is not a scalar value, we must give it a vector, otherwise z.backward() wiil not work\n",
        " z"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.7848, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-wGgZwM7pF6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#to calcualte gradients all we need to do is\n",
        "z.backward() #dz/dx \n",
        "#if requires_grad=True was not specified on x, this will not work."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHuD9A4J70oy",
        "colab_type": "code",
        "outputId": "01905c7f-fa24-40da-e9da-27ea8a29622d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(x.grad)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1.5247, 3.1600, 0.6702])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roxzL7K9783i",
        "colab_type": "code",
        "outputId": "fd32261a-b8dc-44a5-e4f0-ef332fbe8d1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x = torch.randn(3, requires_grad=True)\n",
        "x"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.3715,  1.6048, -1.6478], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZitBPuz9uNs",
        "colab_type": "text"
      },
      "source": [
        "3 ways stop Pytorch from creating gradients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MEmMano9di0",
        "colab_type": "code",
        "outputId": "f5b4719c-bbd4-4bc6-9579-85795aad77e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x.requires_grad_(False) #doesnt require gradient anymore"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.3715,  1.6048, -1.6478])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xx4-dbqe9awj",
        "colab_type": "code",
        "outputId": "56187fc4-f682-446a-f2fc-366ff7f3a930",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y = x.detach() #doesnt require gradient anymore\n",
        "y"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.3715,  1.6048, -1.6478])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViT_vrVa9f9B",
        "colab_type": "code",
        "outputId": "ab428dd1-2362-42c2-ebfb-1152246cc8e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "with torch.no_grad(): #doesnt require gradient anymore\n",
        "  y = x + 2\n",
        "y"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2.3715, 3.6048, 0.3522])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieRXFyXo9pT5",
        "colab_type": "code",
        "outputId": "117f317f-5f4e-4a4e-a4d9-2910eafca57a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "weights = torch.ones(4, requires_grad=True)\n",
        "\n",
        "for epoch in range(3):\n",
        "  model_output = (weights*3).sum()\n",
        "\n",
        "  model_output.backward()\n",
        "\n",
        "  print(weights.grad)\n",
        "\n",
        "  weights.grad.zero_() #we must do this to reset the gradients, otherwise they will keep adding"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjaZDA5a-LMp",
        "colab_type": "code",
        "outputId": "468bc538-79b9-4b02-b238-8bee48b63de9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        }
      },
      "source": [
        "optimizer = torch.optim.SGD(weights, lr=0.01)\n",
        "optimizer.step()\n",
        "optimizer.zero_grad() #same here, we must always reset gradients"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-c0318bdaf409>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#same here, we must always reset gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, lr, momentum, dampening, weight_decay, nesterov)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnesterov\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmomentum\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdampening\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Nesterov momentum requires a momentum and zero dampening\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n\u001b[1;32m     37\u001b[0m             raise TypeError(\"params argument given to the optimizer should be \"\n\u001b[1;32m     38\u001b[0m                             \u001b[0;34m\"an iterable of Tensors or dicts, but got \"\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                             torch.typename(params))\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: params argument given to the optimizer should be an iterable of Tensors or dicts, but got torch.FloatTensor"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "putM5ukp-7_t",
        "colab_type": "text"
      },
      "source": [
        "# Backpropagation\n",
        "And how to calculate gradients with it in Pytorch.\n",
        "1) forwardpass\n",
        "2)\n",
        "3) backwardpass"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFzi3B30-_eh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = torch.tensor(1.0)\n",
        "y = torch.tensor(2.0)\n",
        "\n",
        "w = torch.tensor(1.0, requires_grad=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1IHGNkeE74a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#forward pass\n",
        "y_hat = w * x\n",
        "loss = (y_hat - y)**2\n",
        "loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhetIBMSFGxh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#backward pass\n",
        "loss.backward()\n",
        "w.grad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zgroZKQFbfS",
        "colab_type": "text"
      },
      "source": [
        "Further steps would be\n",
        "1. update weights\n",
        "2. Continue with next forward and backwards passes\n",
        "\n",
        "That's how easy it is to calculate backprop in Pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y016xMNsFp3L",
        "colab_type": "text"
      },
      "source": [
        "# Gradient Descent with Autograd and Backpropagation\n",
        "Automatic grad from pytorch, how it solves quicker stuff for us. \n",
        "\n",
        "First we will do manually, but then we will do it automatically with Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5Yh8qaUFupd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from scratch\n",
        "#f = w * x\n",
        "f = 2 * x\n",
        "\n",
        "X = np.array([1,2,3,4],dtype=np.float32)\n",
        "Y = np.array([2,4,6,8],dtype=np.float32)\n",
        "\n",
        "w = 0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQrc-mYcF_ZZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model prediction\n",
        "def forward(x):\n",
        "  return w * x\n",
        "\n",
        "# loss = MSE, in case of linear regression\n",
        "def loss(y,y_predicted):\n",
        "  return ((y_predicted-y)**2).mean()\n",
        "\n",
        "# gradients\n",
        "# MSE = 1/N * (w*x - y)**2\n",
        "# dJ/dw = 1/N 2x (w*x-y)\n",
        "def gradient(x,y,y_predicted):\n",
        "  return np.dot(2*x, y_predicted -y).mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNd6xXhYHeiR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f'Prediction before traininig: f(5) = {forward(5):.3f}')\n",
        "\n",
        "# Traininig \n",
        "learninig_rate = 0.01\n",
        "n_iters = 20\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  #Prediction = forward pass\n",
        "  y_pred = forward(X)\n",
        "  \n",
        "  # Loss\n",
        "  l = loss(Y,y_pred)\n",
        "\n",
        "  # Gradients\n",
        "  dw = gradient(X,Y,y_pred)\n",
        "\n",
        "  #update weights\n",
        "  w -= learninig_rate * dw\n",
        "\n",
        "  if epoch % 1 == 0:\n",
        "    print(f'epoch {epoch+1}: w = {w:3f}, loss = {l:.8f}')\n",
        "\n",
        "print(f'Prediction after traininig: f(5) = {forward(5):.3f}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJU7c4SLI6rm",
        "colab_type": "text"
      },
      "source": [
        "Example below using Pytorch premade packages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAmva1MBM2Cx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = torch.tensor([1,2,3,4],dtype=torch.float32)\n",
        "Y = torch.tensor([2,4,6,8],dtype=torch.float32)\n",
        "\n",
        "w = torch.tensor(0.0,dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "# model prediction - Same\n",
        "def forward(x):\n",
        "  return w * x\n",
        "\n",
        "# loss = MSE, in case of linear regression - Same\n",
        "def loss(y,y_predicted):\n",
        "  return ((y_predicted-y)**2).mean()\n",
        "\n",
        "\n",
        "\n",
        "print(f'Prediction before traininig: f(5) = {forward(5):.3f}')\n",
        "\n",
        "# Traininig \n",
        "learninig_rate = 0.01\n",
        "n_iters = 100\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  #Prediction = forward pass\n",
        "  y_pred = forward(X)\n",
        "  \n",
        "  # Loss\n",
        "  l = loss(Y,y_pred)\n",
        "\n",
        "  # Gradients = backward pass\n",
        "  l.backward() # dl/dx gradient of loss - pytorch does everything\n",
        "\n",
        "\n",
        "  #update weights\n",
        "  with torch.no_grad():\n",
        "    w -= learninig_rate * w.grad\n",
        "\n",
        "  # zero gradients, because when we acll backward() will accumulate gradients\n",
        "  w.grad.zero_() #_ modifies inplace\n",
        "\n",
        "  if epoch % 10 == 0:\n",
        "    print(f'epoch {epoch+1}: w = {w:3f}, loss = {l:.8f}')\n",
        "\n",
        "print(f'Prediction after traininig: f(5) = {forward(5):.3f}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvC8mp-wv7ZI",
        "colab_type": "text"
      },
      "source": [
        "# Training Pipeline: Model, Loss, and Optimizer\n",
        "Now we will replace all manual places with Pyroch automation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7NbUbb20btF",
        "colab_type": "text"
      },
      "source": [
        "Typical pytorch pipline consists of 3 steps:\n",
        "\n",
        "\n",
        "\n",
        "1.   Design model (input & output size, forward pass)\n",
        "2.   Construct loss & optimizer\n",
        "3.   Traininig loop\n",
        "  *   Forward pass: compute prediction\n",
        "  *   Backward pass: gradients\n",
        "  *   update weights (iterate until we're done)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVh3IwSiwYUi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OL7-nr1vxMp-",
        "colab_type": "text"
      },
      "source": [
        "#### Replacing loss with pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ew1T89swwdRP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = torch.tensor([1,2,3,4],dtype=torch.float32)\n",
        "Y = torch.tensor([2,4,6,8],dtype=torch.float32)\n",
        "\n",
        "w = torch.tensor(0.0,dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "# model prediction - Same\n",
        "def forward(x):\n",
        "  return w * x\n",
        "\n",
        "\n",
        "print(f'Prediction before traininig: f(5) = {forward(5):.3f}')\n",
        "\n",
        "# Traininig \n",
        "learninig_rate = 0.01\n",
        "n_iters = 100\n",
        "\n",
        "loss = nn.MSELoss() #mean squared error\n",
        "optimizer = torch.optim.SGD([w],lr=learninig_rate) #needs some params, weights, lr\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  #Prediction = forward pass\n",
        "  y_pred = forward(X)\n",
        "  \n",
        "  # Loss\n",
        "  l = loss(Y,y_pred)\n",
        "\n",
        "  # Gradients = backward pass\n",
        "  l.backward() # dl/dx gradient of loss - pytorch does everything\n",
        "\n",
        "\n",
        "  #Optimization done automatically via pytorch\n",
        "  optimizer.step()\n",
        "\n",
        "  # We still ned to zero gradiens\n",
        "  optimizer.zero_grad() #_ modifies inplace\n",
        "\n",
        "  if epoch % 10 == 0:\n",
        "    print(f'epoch {epoch+1}: w = {w:3f}, loss = {l:.8f}')\n",
        "\n",
        "print(f'Prediction after traininig: f(5) = {forward(5):.3f}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvJTAKzrxa23",
        "colab_type": "text"
      },
      "source": [
        "#### Replacing forward with Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36QBXKvIxTGw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = torch.tensor([[1],[2],[3],[4]],dtype=torch.float32) #new shape\n",
        "Y = torch.tensor([[2],[4],[6],[8]],dtype=torch.float32)\n",
        "\n",
        "n_samples, n_features = X.shape #(4,1)\n",
        "#don't need to specify weights anymore, just model\n",
        "\n",
        "X_test = torch.tensor([5],dtype=torch.float32) #model needs a tensor to be inputed, so we create one\n",
        "\n",
        "input_size = n_features #1\n",
        "output_size = n_features #1\n",
        "\n",
        "model = nn.Linear(input_size, output_size) #needs input size and output size, but X and Y need to be modified a little for shapes\n",
        "\n",
        "print(f'Prediction before traininig: f(5) = {model(X_test).item():.3f}') #same 5 value but as tensor inputed.\n",
        "\n",
        "# Traininig \n",
        "learninig_rate = 0.03\n",
        "n_iters = 8\n",
        "\n",
        "loss = nn.MSELoss() #mean squared error\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learninig_rate) #updated optimizer\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  #Prediction = forward pass\n",
        "  y_pred = model(X)\n",
        "  \n",
        "  # Loss\n",
        "  l = loss(Y,y_pred)\n",
        "\n",
        "  # Gradients = backward pass\n",
        "  l.backward() # dl/dx gradient of loss - pytorch does everything\n",
        "\n",
        "\n",
        "  #Optimization done automatically via pytorch\n",
        "  optimizer.step()\n",
        "\n",
        "  # We still ned to zero gradiens\n",
        "  optimizer.zero_grad() #_ modifies inplace\n",
        "\n",
        "  if epoch % 1 == 0:\n",
        "    [w,b]=model.parameters()\n",
        "    print(f'epoch {epoch+1}: w = {w[0][0].item():3f}, loss = {l:.8f}') #.item() is called to return number, not a tensor.\n",
        "\n",
        "print(f'Prediction after traininig: f(5) = {model(X_test).item():.3f}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NE_ieoa-zXxI",
        "colab_type": "text"
      },
      "source": [
        "# What if we need more than 2 layers model?\n",
        "Custom model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gk5hXuaSyEHD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = torch.tensor([[1],[2],[3],[4]],dtype=torch.float32) #new shape\n",
        "Y = torch.tensor([[2],[4],[6],[8]],dtype=torch.float32)\n",
        "\n",
        "n_samples, n_features = X.shape #(4,1)\n",
        "#don't need to specify weights anymore, just model\n",
        "\n",
        "X_test = torch.tensor([5],dtype=torch.float32) #model needs a tensor to be inputed, so we create one\n",
        "\n",
        "input_size = n_features #1\n",
        "output_size = n_features #1\n",
        "\n",
        "#model = nn.Linear(input_size, output_size) #needs input size and output size, but X and Y need to be modified a little for shapes\n",
        "\n",
        "#custom - this is how you design model\n",
        "class LinearRegression(nn.Module):\n",
        "  def __init__(self,input_dim, output_dim):\n",
        "    super(LinearRegression, self).__init__()\n",
        "    #define layers\n",
        "    self.lin = nn.Linear(input_dim, output_dim)\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.lin(x)\n",
        "\n",
        "model = LinearRegression(input_size,output_size)\n",
        "\n",
        "print(f'Prediction before traininig: f(5) = {model(X_test).item():.3f}') #same 5 value but as tensor inputed.\n",
        "\n",
        "# Traininig \n",
        "learninig_rate = 0.03\n",
        "n_iters = 8\n",
        "\n",
        "loss = nn.MSELoss() #mean squared error\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learninig_rate) #updated optimizer\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  #Prediction = forward pass\n",
        "  y_pred = model(X)\n",
        "  \n",
        "  # Loss\n",
        "  l = loss(Y,y_pred)\n",
        "\n",
        "  # Gradients = backward pass\n",
        "  l.backward() # dl/dx gradient of loss - pytorch does everything\n",
        "\n",
        "\n",
        "  #Optimization done automatically via pytorch\n",
        "  optimizer.step()\n",
        "\n",
        "  # We still ned to zero gradiens\n",
        "  optimizer.zero_grad() #_ modifies inplace\n",
        "\n",
        "  if epoch % 1 == 0:\n",
        "    [w,b]=model.parameters()\n",
        "    print(f'epoch {epoch+1}: w = {w[0][0].item():3f}, loss = {l:.8f}') #.item() is called to return number, not a tensor.\n",
        "\n",
        "print(f'Prediction after traininig: f(5) = {model(X_test).item():.3f}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsCC7ltiz9x1",
        "colab_type": "text"
      },
      "source": [
        "#### Pytorch can do most of the work for use\n",
        "- We need to design model\n",
        "- Know which loss & optimizer to use\n",
        "- dont have to worry about underlying algorithms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59BGVKRSz9cu",
        "colab_type": "text"
      },
      "source": [
        "# Linear Regression\n",
        "Repetition of learned concetps, and quickly implement algorithm, typical pytorch pipline consists of 3 steps:\n",
        "\n",
        "1.   Design model (input & output size, forward pass)\n",
        "2.   Construct loss & optimizer\n",
        "3.   Traininig loop\n",
        "  *   Forward pass: compute prediction\n",
        "  *   Backward pass: gradients\n",
        "  *   update weights (iterate until we're done)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onwcwu5M0UiA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import torch\n",
        "#import torch.nn as nn\n",
        "#import numpty as np\n",
        "from sklearn import datasets \n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVKIkJKX1bCw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Step 0 - Prepare data\n",
        "X_numpy,y_numpy = datasets.make_regression(n_samples=100, n_features=1, noise=20, random_state=1)\n",
        "\n",
        "X = torch.from_numpy(X_numpy.astype(np.float32))\n",
        "y = torch.from_numpy(y_numpy.astype(np.float32))\n",
        "y = y.view(y.shape[0], 1) #reshaping y from row to column\n",
        "\n",
        "n_samples, n_features = X.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmGC_H0f1T-8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Step 1 - Model\n",
        "input_size = n_features\n",
        "output_size = 1\n",
        "\n",
        "model = nn.Linear(input_size,output_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KRaTV_01WLC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Step 2 - Loss and optimizer\n",
        "learninig_rate=0.01\n",
        "\n",
        "criterion = nn.MSELoss() #Mean squared error los\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learninig_rate) #input params and lr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehI3qMgZ1Y4K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Step 3 - traininig loop\n",
        "num_epochs = 100\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  #forward pass and loss\n",
        "  y_predicted = model(X)\n",
        "  loss = criterion(y_predicted, y)\n",
        "\n",
        "  #backward pass\n",
        "  loss.backward()\n",
        " \n",
        "  #update\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad() #to reset gradients\n",
        "\n",
        "  if (epoch+1) % 10 == 0:\n",
        "    print(f'epoch:{epoch+1}, loss={loss.item():.4f}')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTv_i8Jg3c9Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#plotting \n",
        "predicted = model(X).detach().numpy() #prevent from being tracked from computational graph, and convert into numpy\n",
        "\n",
        "plt.plot(X_numpy, y_numpy, 'ro')\n",
        "plt.plot(X_numpy, predicted, 'b')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9ZoHFWL5fP9",
        "colab_type": "text"
      },
      "source": [
        "# Logistic Regression implementation\n",
        "\n",
        "Same 3 steps as usual, with minor changes:\n",
        "1.   Design model (input & output size, forward pass)\n",
        "2.   Construct loss & optimizer\n",
        "3.   Traininig loop\n",
        "  *   Forward pass: compute prediction\n",
        "  *   Backward pass: gradients\n",
        "  *   update weights (iterate until we're done)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9SstqKf5f5S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVrw05ba58du",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#0 Prepare data\n",
        "\n",
        "bc = datasets.load_breast_cancer()\n",
        "X,y = bc.data, bc.target\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "#print(n_samples, n_features) 569 30\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=1)\n",
        "\n",
        "#scale features\n",
        "sc = StandardScaler() #zero mean and variance - good for logistic regression\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "#convert to torch tensors\n",
        "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
        "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
        "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
        "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
        "\n",
        "\n",
        "#reshape y tensors\n",
        "y_train = y_train.view(y_train.shape[0],1) #pytorch premade to reshape y values, making 1 coloumn vector\n",
        "y_test = y_test.view(y_test.shape[0],1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDFK8sn052uw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#1 Model\n",
        "# f = wx + b, sigmoid function at the end\n",
        "\n",
        "class LogisticRegression(nn.Module):\n",
        "  def __init__(self, n_input_features):\n",
        "    super(LogisticRegression, self).__init__()\n",
        "    self.linear = nn.Linear(n_input_features, 1)\n",
        "  \n",
        "  def forward(self,x):\n",
        "    y_predicted = torch.sigmoid(self.linear(x))\n",
        "    return y_predicted\n",
        "\n",
        "\n",
        "model = LogisticRegression(n_features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxygTp8k54Kq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#2 Loss and optimizer\n",
        "learninig_rate = 0.01\n",
        "cirterionn = nn.BCELoss() #binary cross entropy loss\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learninig_rate) #adam performed better than SGD"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-l66A9Lx56pq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#3 Training loop\n",
        "num_epochs = 150\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  #forward pass\n",
        "  y_predicted = model(X_train)\n",
        "  loss = criterion(y_predicted, y_train)\n",
        "  \n",
        "  #backward pass\n",
        "  loss.backward()\n",
        "  \n",
        "  #update weights\n",
        "  optimizer.step()\n",
        "\n",
        "  #zero gradients\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  #print some information\n",
        "  if (epoch+1) % 10 == 0:\n",
        "    print(f'Epoch: {epoch+1}, loss = {loss.item():.4f}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJ9_BNXE573a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Evaluate model\n",
        "with torch.no_grad():\n",
        "  y_predicted = model(X_test)\n",
        "\n",
        "  #if y_predicted > 0.5, we say it's 1, if less we say it's 0\n",
        "  y_predicted_cls = y_predicted.round() #will round to nearest integer\n",
        "\n",
        "  #accuracy\n",
        "  acc = y_predicted_cls.eq(y_test).sum()/float(y_test.shape[0])\n",
        "  print(f'Accuracy = {acc:.4f}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bVNRmeaAyo4",
        "colab_type": "text"
      },
      "source": [
        "# Pytorch Dataset and DataLoader - Batch Training\n",
        "\n",
        "it's faster and wiser to do iterations and update weights in batches, rather than in a whole dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ry53_HrFAz9R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "epoch = 1 forward and backward pass of ALL training samples\n",
        "\n",
        "batch_size = number of traininig samples in one forward and backward pass\n",
        "\n",
        "number of iterations = number of passes, each pass uses [batch_size] number of samples\n",
        "e.g. 100 samples, batch_size=20 ---> 100/20 = 5 iterations for 1 epoch\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yzcu-tNBejx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGq5iosBBqCR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#getting dataset\n",
        "\n",
        "class WineDatatset(Dataset):\n",
        "  def __init__(self):\n",
        "    #data loading\n",
        "    xy = np.loadtxt('./wine.csv', delimiter=\",\", dtype=np.float32, skiprows=1)\n",
        "    self.x = torch.from_numpy(xy[:,1:])\n",
        "    self.y = torch.from_numpy(xy[:,[0]]) # n_samples, 1 \n",
        "    self.n_samples = xy.shape[0]\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    return self.x[index], self.y[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.n_samples\n",
        "\n",
        "dataset = WineDatatset()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEWMUIH7C5Hb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "first_data = dataset[0]\n",
        "features, labels = first_data\n",
        "print(features,labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUXnyl8tDfWi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Dataloader - Pytorch\n",
        "\n",
        "dataloader = DataLoader(dataset=dataset, batch_size=4, shuffle=True, num_workers=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFZz_J7JDyiW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataiter = iter(dataloader)\n",
        "data = dataiter.next()\n",
        "features,labels = data\n",
        "print(features,labels) #we see 4, since batch size is 4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayfVCj7ZEJdx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# traininig loop\n",
        "num_epochs = 2\n",
        "total_samples = len(dataset)\n",
        "n_iterations = math.ceil(total_samples/4)\n",
        "print(total_samples, n_iterations)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6hWQtNAEnDT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(num_epochs):\n",
        "  for index, (inputs,labels) in enumerate(dataloader):\n",
        "    # forward\n",
        "\n",
        "    # backward\n",
        "    \n",
        "    #update weights + zero gradients\n",
        "    if (index+1)%5 ==0:\n",
        "      print(f'epoch {epoch+1}/{num_epochs},step {index+1}/{n_iterations},inputs{inputs.shape}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffPpsPUiFHtL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#python has some builtin datasets - torchvision.datasets.MNIST()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQoPZ-4qLQ8_",
        "colab_type": "text"
      },
      "source": [
        "# Dataset Transforms\n",
        "All available transforms are found here: https://pytorch.org/docs/stable/torchvision/transforms.html\n",
        "\n",
        "e.g. On images\n",
        "______________\n",
        "CenterCrop, Grayscale, Pad, RandomAffine, RandomCrop, RandomHorizontalFlip, RandomRotation, Resize, Scale\n",
        "\n",
        "On Tensors\n",
        "______________\n",
        "LinearTransformation, Normalize, RandomErasing... etc\n",
        "\n",
        "\n",
        "even multiple transfrorms or custom transforms are possible..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26y605ZtLlnY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#getting dataset\n",
        "\n",
        "class WineDataset(Dataset):\n",
        "  def __init__(self,transform=None):\n",
        "    #data loading\n",
        "    xy = np.loadtxt('./wine.csv', delimiter=\",\", dtype=np.float32, skiprows=1)\n",
        "    self.n_samples = xy.shape[0]\n",
        "    \n",
        "    #note we dont convert to tensor here\n",
        "    self.x = xy[:,1:]\n",
        "    self.y = xy[:,[0]]  \n",
        "\n",
        "    self.transform = transform\n",
        "    \n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    sample =  self.x[index], self.y[index]\n",
        "\n",
        "    if self.transform:\n",
        "      sample = self.transform(sample)\n",
        "\n",
        "    return sample\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.n_samples\n",
        "\n",
        "\n",
        "#custom tranform to apply on our dataset\n",
        "\n",
        "class ToTensor(): #turns dataset into tensor \n",
        "  def __call__(self,sample):\n",
        "    inputs, targets = sample\n",
        "    return torch.from_numpy(inputs), torch.from_numpy(targets)\n",
        "\n",
        "class MulTransform: #Multiplier of dataset inputs \n",
        "  def __init__(self,factor):\n",
        "    self.factor = factor\n",
        "\n",
        "  def __call__(self,sample):\n",
        "    inputs, targets = sample\n",
        "    inputs *= self.factor\n",
        "    return inputs, targets\n",
        "\n",
        "\n",
        "dataset = WineDataset(transform=ToTensor()) #with class ToTensor()\n",
        "first_data = dataset[0]\n",
        "features,labels = first_data\n",
        "print(type(features),type(labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZscCdQhLMvrW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = WineDataset() #without ToTensor() transform\n",
        "first_data = dataset[0]\n",
        "features,labels = first_data\n",
        "print(features)\n",
        "print(type(features),type(labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17GY3l_wNZfx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Multiple transforms with compose - To tensor and multiplic\n",
        "\n",
        "composed = torchvision.transforms.Compose([ToTensor(), MulTransform(2)])\n",
        "dataset = WineDataset(transform=composed)\n",
        "first_data = dataset[0]\n",
        "features,labels = first_data\n",
        "print(type(features),type(labels))\n",
        "print(features) #We see inputs are multiplied\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhlDuIj-PIG2",
        "colab_type": "text"
      },
      "source": [
        "# Softmax and Cross Entropy\n",
        "\n",
        "Most common functions in Neural Nets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gznDrLDvOFQp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#softmax - squashes output to be between 0 to 1, sum of values is 1. Making them probabilities\n",
        "\n",
        "def softmax(x):\n",
        "  return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
        "\n",
        "x = np.array([2.0,1.0,0.1])\n",
        "outputs = softmax(x)\n",
        "print('softmax numpy', outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbHxAeyUPuqx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pytorch version\n",
        "x = torch.tensor([2.0,1.0,0.1])\n",
        "outputs = torch.softmax(x,dim=0)\n",
        "print(outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ym_9ixfqP7q8",
        "colab_type": "text"
      },
      "source": [
        "Usually **Softmax** is cmobined with **Cross-Entropy** Loss.\n",
        "\n",
        "CEL - this measures performace of our classification model, whose output is between 0 and 1.\n",
        "\n",
        "*   Good prediction has low cross entropy loss.\n",
        "*   Bad prediction has hight cross entropy loss.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ref-nwBNP2e8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cross_entropy(actual, predicted):\n",
        "  loss = np.sum(actual * np.log(predicted))\n",
        "  return loss\n",
        "\n",
        "Y = np.array([1,0,0]) #one-hot encoded\n",
        "\n",
        "#y_pred has probabilities\n",
        "Y_pred_good = np.array([0.7,0.2,0.1])\n",
        "Y_pred_bad = np.array([0.1,0.3,0.6])\n",
        "l1 = cross_entropy(Y,Y_pred_good)\n",
        "l2 = cross_entropy(Y,Y_pred_bad)\n",
        "print(f'Loss1 numpy: {l1:.4f}') #low because good\n",
        "print(f'Loss2 numpy: {l2:.4f}') #high because bad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Pe5Jik4SK0u",
        "colab_type": "text"
      },
      "source": [
        "# Pytorch version of Cross entropy and Softmax together\n",
        "\n",
        "*   already applies LogSoftmax, + negative log likelikehoodloss\n",
        "*   we just need to put correct classes, not one-hot encoding\n",
        "*   we dont need to indicate softmaxt on last layers on pytorch, crossentropy does that.\n",
        "\n",
        "\n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffREteuIRFQh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = nn.CrossEntropyLoss() #already applies LogSoftmax, + negative log likelikehood loss\n",
        "# we just need to put correct classes, not one-hot encoding\n",
        "# we dont need to indicate softmaxt on last layers\n",
        "\n",
        "Y = torch.tensor([0]) #n_sanmples x n_clasess = 1x3\n",
        "Y_pred_good = torch.tensor([[2.0,1.0,0.1]])\n",
        "Y_pred_bad = torch.tensor([[0.5,2.0,0.3]])\n",
        "\n",
        "l1 = loss(Y_pred_good, Y)\n",
        "l2 = loss(Y_pred_bad, Y)\n",
        "\n",
        "print(l1.item())\n",
        "print(l2.item())\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6a5ydgEXR_DB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_,predictions1 = torch.max(Y_pred_good,1)\n",
        "_,predictions2 = torch.max(Y_pred_bad,1)\n",
        "print(predictions1) #in this case we choose 0 label\n",
        "print(predictions2) #in this case we choose 1 label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPf6BmMjSZcQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 3 samples\n",
        "Y = torch.tensor([2,0,1]) #n_sanmples x n_clasess = 3x3\n",
        "\n",
        "#n_sanmples x n_clasess = 3x3\n",
        "Y_pred_good = torch.tensor([[0.1,1.0,2.1],[2.0,1.0,0.1],[0.1,3.0,0.1]])\n",
        "Y_pred_bad = torch.tensor([[2.1,1.0,0.1],[0.1,1.0,2.1],[0.1,3.0,0.1]])\n",
        "\n",
        "l1 = loss(Y_pred_good, Y)\n",
        "l2 = loss(Y_pred_bad, Y)\n",
        "\n",
        "print(l1.item())\n",
        "print(l2.item())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWuoyEM_TBpZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_,predictions1 = torch.max(Y_pred_good,1)\n",
        "_,predictions2 = torch.max(Y_pred_bad,1)\n",
        "print(predictions1) #in this case we choose 0 label\n",
        "print(predictions2) #in this case we choose 1 label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zy5zwGwKTwbY",
        "colab_type": "text"
      },
      "source": [
        "# Neural Net with Softmatx - Multiclass\n",
        "E.g. predicting dog or cat, or bird etc..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_w7IGfmTzSW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NeuralNet2(nn.Module):\n",
        "  def __init__(self,input_size,hidden_size,num_classes):\n",
        "    super(NeuralNet2, self).__init__()\n",
        "    self.linear1 = nn.Linear(input_size,hidden_size) #linear layer, with input size, hidden size\n",
        "    self.reul = nn.ReLU() #Activation function in between\n",
        "    self.linear2 = nn.Linear(hidden_size, num_classes) #last layer, hidden size + output num_classes\n",
        "\n",
        "  def forward(self,x):\n",
        "    out = self.linear1(x)\n",
        "    out = self.relu(out)\n",
        "    out = self.linear2(out)\n",
        "    #no softmax at the end\n",
        "    return out\n",
        "\n",
        "model = NeuralNet2(input_size=28*28, hidden_size=5, num_classes=3)\n",
        "criterion = nn.CrossEntropyLoss() # (applies Softmax)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DteOKMWoVbtf",
        "colab_type": "text"
      },
      "source": [
        "# Neural Net with Sigmoid (BINARY)\n",
        "E.g. predicting if it's a dog. YES/NO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SA_hMq6vVpnE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NeuralNet1(nn.Module):\n",
        "  def __init__(self,input_size,hidden_size):\n",
        "    super(NeuralNet1, self).__init__()\n",
        "    self.linear1 = nn.Linear(input_size, hidden_size) #set up laye1 \n",
        "    self.relu = nn.ReLu()\n",
        "    self.linear2 = nn.Linear(hidden_size,1) #last layer has output size 1. Always fixed in this case\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.linear1(x)\n",
        "    out = self.relu(out)\n",
        "    out = self.linear2(out)\n",
        "    #sigmoid at the end \n",
        "    y_pred = torch.sigmoid(out) #must implement\n",
        "    return y_pred\n",
        "\n",
        "model = NeuralNet1(input_size=28*28, hidden_size=5)\n",
        "criterion = nn.BCELoss() #for criterion we use Binary Cross Entropy Loss."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4U0Q5X7O4tv_",
        "colab_type": "text"
      },
      "source": [
        "# Activation Functions\n",
        "- Applier a linear transforamtion to layer output, and decide if neuron should be activated or not.\n",
        "- We need these activations, to make linear model applicable to complex tasks where simple linear models, are not able to perform."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUut9cu-5IcX",
        "colab_type": "text"
      },
      "source": [
        "## Most popular activation functions\n",
        "1. Step Function\n",
        "2. Sigmoid\n",
        "3. TanH\n",
        "4. ReLU\n",
        "5. Leaky ReLU\n",
        "6. Softmax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFMKG7mY5xrF",
        "colab_type": "text"
      },
      "source": [
        "### Step Function\n",
        "* will output 1 if x >= 0, - Neuron will be activated\n",
        "* Else, if less than 0, will not activate neuron\n",
        "#### not used in practice"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ww634lUr50Kx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Sigmoid, we've seen previously, used in Binary classificaiton"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwwJg_jd6Awo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TanH Function - Basically scaled sigmoid function and little bit shifted. Outputs avlues (-1,1)\n",
        "# A good choice"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHqamgxO6IE-",
        "colab_type": "text"
      },
      "source": [
        "## ReLU \n",
        "Most popular function in most networks.\n",
        "\n",
        "![alt text](https://qph.fs.quoracdn.net/main-qimg-d23ac99265ab19599e71c9d1a3cb089a)\n",
        "\n",
        "f(x) = max(0,x)\n",
        "\n",
        "* Will output 0 for negative values\n",
        "* will output input for positive values. (Linear function for positive numbers)\n",
        "\n",
        "\n",
        "If you don't know which Activation function to use, always go for ReLU.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHR55fDj63E1",
        "colab_type": "text"
      },
      "source": [
        "# Leaky ReLU function\n",
        "* Positive remian the samin\n",
        "* Negatives are going to be multiplied with very smal value, like 0.001.\n",
        "* Tries to solve vanishing gradien problem. (in 0 values gradien is always 0, so weights in the 0 values will never be updated, hence with small values, it will slightly update them)\n",
        "* If weights don't update during traininig us Leaky ReLU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tggGrL8Y66Xo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Softmax, we've done it in previous lectures. Get probability as an output. \n",
        "#Good choice in last layer of multiclass classification/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaY4juOr8Szl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36_dyL2o7VJK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#first way how to use it\n",
        "class NeuralNet(nn.Module):\n",
        "  def __init__(self,input_size,hidden_size):\n",
        "    super(NeuralNet, self).__init__()\n",
        "    self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.linear2 = nn.Linear(hidden_size,1)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self,x):\n",
        "    out = self.linear1(x) #here we use premade linear and input inputs\n",
        "    out = self.relu(out) #here we put previous results into relu\n",
        "    out = self.linear2(out) #we 2nd linear layer\n",
        "    out = self.sigmoid(out) #we run it via sigmoin in last layer, probably as for binary classification (yes/no)\n",
        "    return out\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBNJcfYZ8O5K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cb022f73-f54e-4cc0-9f2a-727367395165"
      },
      "source": [
        "#second way to use it directly. Both ways are good, it's your preference how you like your code\n",
        "\n",
        "class NeuralNet(nn.Module):\n",
        "  def __init__(self,input_size,hidden_size):\n",
        "    super(NeuralNet, self).__init__()\n",
        "    self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "    self.linear2 = nn.Linear(hidden_size,1)\n",
        "\n",
        "  def forward(self,x):\n",
        "    out = torch.relu(self.linear1(x)) #directly, just from torch API\n",
        "    out = torhc.sigmoid(self.linear2(out)) #directly, just from torch API\n",
        "    return out\n",
        "\n",
        "\n",
        "#tanh, sigmoid, leaky relu, softmax, are also available in torch API. \n",
        "\n",
        "#also via pytorch functional\n",
        "F.leaky_relu\n",
        "F.tanh\n",
        "F.sigmoid\n",
        "F.softmax #etc..."
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function torch.nn.functional.softmax>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_GvgYfB9fyW",
        "colab_type": "text"
      },
      "source": [
        "# Feed-Forward Neural Network\n",
        "We will build, mnist clasification NN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLpI84B08xBK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MNIST\n",
        "# Dataloader, transformation\n",
        "# Multilayer Neural net, activation function\n",
        "# Loss and Optimizer\n",
        "# Traininig loop (Batch traininig)\n",
        "# Model evaluation\n",
        "# GPU support"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWC0iH5w9y8C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#device config\n",
        "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "#hyper parameters\n",
        "input_size = 784 # because images are 28 x 28 (when we flatted to 1d it will be 28*28 = 784)\n",
        "hidden_size = 100 #can be any here\n",
        "num_classes = 10 #because we have 10 digins from 0 to 9\n",
        "num_epochs = 2 #can adjust\n",
        "batch_size = 100\n",
        "learninig_rate = 0.001\n",
        "\n",
        "# Mnist data importing\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True,\n",
        "                                           transform=transforms.ToTensor(),\n",
        "                                           download=True)\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data', train=False,\n",
        "                                           transform=transforms.ToTensor())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGmkw9bA99rg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data loader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size,\n",
        "                                           shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HGv33i3_B8a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dce34ad3-3311-4ec0-8a71-33b016b78b7d"
      },
      "source": [
        "#view batch, this example data\n",
        "examples = iter(train_loader)\n",
        "samples,labels = examples.next()\n",
        "print(samples.shape, labels.shape)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([100, 1, 28, 28]) torch.Size([100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqOO98Ga_L0w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "outputId": "29088db6-ea0e-4dcc-974e-efa6cc0062fc"
      },
      "source": [
        "#lets plot it, see the images\n",
        "for i in range(9):\n",
        "  plt.subplot(3,3,i+1)\n",
        "  plt.imshow(samples[i][0], cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU4AAAD7CAYAAAAFI30bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOydWXBk13mYv9P7vgBoNNBo7MBghrNwNnKGpMQtlETKi+xS5Ihlu6RyHD+lKq7Kg+W85NVPqXJVUpVSKi455cR2ZKciqSKZYUiR0nDE4WzkbMBgXxpooBegF/S+3Dxg7hEwnBkCM41eMPer6mqg+wL39P37/PecfxWKoqChoaGhsXt0jR6AhoaGRquhKU4NDQ2NPaIpTg0NDY09oilODQ0NjT2iKU4NDQ2NPaIpTg0NDY098kSKUwjxphDirhBiWgjxvVoNSqOxaHI9uGiyrQ3iceM4hRB6YBL4ChACLgNvK4pyp3bD06g3mlwPLppsa4fhCf72eWBaUZRZACHE3wHfAB4qBCHE0x5tH1MUxdfoQXwBmlz3TivIFfYoW02uD5frk2zVe4Clbb+H7r2m8XAWGj2AXaDJde+0glxBk+1eeahcn2TFuSuEEH8C/Ml+n0ejvmhyPZhoct0dT6I4l4Hebb8H7722A0VRvg98H7Slf4ugyfXg8oWy1eS6O55kq34ZGBVCDAohTMC3gR/XZlgaDUST68FFk22NeOwVp6IoZSHEvwbeAfTAXymKcrtmI9NoCJpcDy6abGvHY4cjPdbJtKX/VUVRzjZ6ELVGk6sm1wPKQ+WqZQ5paGho7JF996o3I0II+VBRFAUhBBaLBb1ej8lkwmAw7DhOURQURSGfz1MulykWixSLxUZ9jKcenU6HEAK9Xo9Op8NoNKLX6zEajRiNRim7arXK5uYmpVKJarUqH5VKpdEfQaNFeeoUpxACq9UqFaPBYKBSqZDP57FarZw+fZrOzk4GBwcJBoMYDAbMZjOKolCpVCgWi1y9epVQKMTMzAzj4+NoVfTrj9FoxGq1YjabaW9vx2azMTQ0hM/nIxgMMjg4KGWXSqV45513mJ+fJ5VKkUqlyGQyxGIxTXYaj8VTpTiFEOh0OsxmM1arVa5MyuUyer0em81Gb28vvb29HDt2jJGREUwmExaLBYByuUwulyObzaLT6VhfX0en02krlzqirv6NRiM2mw2LxUJHRwcOh0Pe7EZHRzl69KiUXSKRYHp6mmKxiNFoxGDY+tonk0nK5TLVarWRH0mjBXlqFKfZbKa7uxuXy8WZM2cYGBjAbrfjdDqpVquUSiWMRiMDAwO43W46OjrweDzo9Xo50arVKuVymRdeeIFDhw5hNBpZWloik8mwsbGhTcB9RKfTodPp6OzspK2tjeHhYZ5//nkcDgdtbW1YrVZ8Ph8OhwOv14vX60UIgdFoRKfT8dWvfpUzZ86QyWTIZrOsrKxw+/ZtYrEYly9fJplMNvojarQQT43iNJlMBINBfD4fX/nKVzh16hQej0dOsGq1ihACg8GATvdon5nb7aZarbK8vMyFCxfY2NgglUppinMf0ev16PV6aUY5d+4c3/72t3E6nbhcLnlzexBms5kXX3wRgFKpRLlcZmZmhkAgwOzsLOPj45ri1NgTB15xOp1OOjs78fl8vPTSS3R1ddHf34/b7ZaOIHiwwwigWCySzWal40h1SOh0Ojo6Ojh8+DDLy8usrKxQKpUa8REPLHq9HrPZjNlsZnBwELfbzdGjRxkZGWF4eBiHw4HJZHroja5SqZDL5aR5RnUiGQwGPB4PAwMDKIpCb28viqKwsbFBLper86fUaEUOvOLs7OzkxRdfZGBggLfffptAIIDFYvmcx/xhZLNZlpeX0ev1+Hw+aTczGo309/fz6quvcuvWLa5fv65NuhpjNBrltvtrX/saw8PDnDp1iiNHjkjvOfBQGZZKJRKJBAAdHR1y1arX6/H7/bhcLjo6Orh8+TIOh4Pbt29rMtTYFQdWcbpcLux2O8FgkIGBAYLBIG63G7vdLleN+XyebDZLpVKRToJKpUK1WpWhR/F4nMXFRUwmE4VCAbvdjt/vl6EvZrMZk8n0hQpY44tRzSROpxO3243NZqO7uxuv18vAwACBQACv14vVaqVarVIsFimVSmxublIul8lmsxSLRRRFoVqtUigUWF9fRwiB3+/HZrPR3t6Ox+MBtrbwdrud7u5uCoUCc3NzDb4CTxd6vR6Px4PZbMbhcGC1Wh95fKFQIJ/PUygUSCaTVCoVGWJWbw6k4tTpdJw4cYIzZ85w+PBhXn31VRwOB+3t7XJrDrC4uMjt27fJZDLE43EpkHw+L21ha2trTE1N4Xa7+fKXv0xXVxdf/epXOXz4sHQcqYpY4/ERQsgb2/nz53nttddob29ndHQUm82Gx+PBZDLJyZXNZonH46yvr/OrX/2KWCzG+Pg44XBYTjBFUaTTLxAI4Ha7+eY3v8kbb7whdw6dnZ28+eabrK2tsbCwwMzMTIOvxMFHNXW5XC5ef/11+vv7OX36NM8888yOY+6Pn15YWGBqaoqlpSU++OADkskk0WiUXC4nj6kXB05xqls4n89Hf38/wWCQQCCA2WzGYDDIlUqlUmF9fZ3l5WU2NzdZW1uTK5R8Pk+xWKRQKBCNRpmZmcHr9TIyMoJeryefzwNIZ9J2Zayxd1S7o9PpxOPx0NPTw+joKB0dHYyNjWE2m+UkUiMbcrkcGxsbRKNRFhYWWFtbY2JiglAoRKFQ2DGZjEYj6XQal8tFOBxmc3MTm80m43n9fj86nQ6Hw4FOp6v7JHzaUEP/XC4XPT099Pf3MzY2xvHjx+UxD1KcVqsVRVGkqcVgMJBOpymVSlQqlbqGBR4oxanaHT0eD+fPn+fVV1/F6/XKOMx0Ok0ul+PChQvMzMwwOTnJ+Pg4pVKJTCazQ6mqW3ZViaqZQtu3Bg6Hg0AgQCgU0pTnY2Iymejs7MTtdvPbv/3bnDx5Ugawq7ZkQGb7RCIR1tfXmZiY4MMPPyQejzM+Pk46nWZjY4NMJvO5SVQqlYhEIiSTSX75y19SKBR45plneOONNzAYDHIn0t3dTSAQIJ1Oa172fcBgMGA0Gunr6+P111+nq6uLl156ie7ubjo7O3ccu/3Gpf7c2dmJ2WxmeHiYI0eOEI1G+eEPf8j09DRra2vE4/H6fZa6nakOGAwGOjo66O7uZnBwkNHRURnkXiqVyOfzpFIpbt68yaVLl+TWTJ2Uj0JVpJVKRQrSYrFIW+oXhTBpPBjVw+3z+Xjuued47bXXsFgs8manoirDVCrF6uoqU1NTXLhwgUQiIbfnD0NRFDY3N8lms0xNTaHT6bBYLFQqFUwmEw6Hg2q1itvtxu12UyqVNMW5D6ipzB0dHZw/f55AIMDx48dpb28HdipLIcTnlKfT6cTpdAJIxXnt2jVSqRTpdFpTnHvF6XTKlebrr79Ob2+vzPpRt9/xeJwPPviAtbU1PvnkE+bn52XQ+uNuy/L5vJyQWgzn42G32zlz5gzBYJCenh4Z8QCwubnJysoKmUyGhYUFUqkUc3NzLC8vEwqFiEQism7AblAUhWw2y/r6unQoqfG7er2erq4uRkdHAYhEItp2vcaMjIxw+vRphoaGOHTokExceBDZbJa5uTkKhQL9/f20tbV97hibzcarr77K0NAQH330EdevXyeZTBKJRPZ9Pn6h4hRC/BXwm0BEUZRj915rA/4eGADmgd9TFGVj/4b5aNxuN6dPn6anp4dvfOMbDA8Py21eKpVieXmZqakpfvCDHzA3N0cmk5He1yehWCySSCTkNr+VaBa5ulwuXnzxRQ4dOkRfX9+OlWY6nebmzZtEIhE+/PBDQqEQi4uLrKysSM/5XslkMkSjUVKplLSNqTULgsEgR44cIZlMtnQNgmaR7f0cPXqU3//938fn83Ho0CEsFstDnaqbm5tcvXqVdDqNzWZ7oOK02+289dZblEolbDYbpVKJhYUFYrHYvs/H3ewvfwC8ed9r3wPeUxRlFHjv3u91x2q10tHRQSAQYHR0lOHhYdxut3QmqA6giYkJpqenpce8XC7veVIYDAbcbjdtbW2YTCbg146K3a54mowf0CRyVdMp1UmUy+WIRqOEQiHu3LnDnTt3WF5eJh6PSxvm40wMtbJVOp0mkUgQj8dJJBJUKhW54jx06BBdXV077KstyA9oItn6/X5GRkbo7e3F5/Phdrtl9apSqUShUGBxcZFr165x584dQqEQS0tLTE9Pc/fuXa5du8alS5d2fA9U+auORZPJhN1u3+FI3E++cMWpKMovhBAD9738DeDVez//NfAB8Gc1HNeu6OzsZGRkhOPHj/M7v/M7Mr/cZDJJm+bExAR/8zd/QzQaZXV1VXpb94rFYpEZK263G/h10Q819KWVaGa5rq2tMTk5yY0bN/ibv/kbYrEYuVxOxts+CWp67PT0NLdu3cLv93PixAkcDgdnz57lxIkTrK+vc+HCBTKZDIlEouV2E80kW6PRyPnz53nmmWd21HhQI1wymQy5XI5/+qd/4oMPPqCnp4djx44RiUT40Y9+RCQS4eOPP8br9XLs2DHOnDlDIBDg+eef37HNV8MNI5FIcyjOh+BXFCV87+dVwP+wA/eja5564b1eL8FgkK6uLjweD263G4PBgKIo0jMaiURYW1tjY2Pjsbfnqg3MarXicDjkSkQNui6VSi2nOB9CXeWqhpyoqZCqg011wqnB7WotzVpcY9URmMvlSKfTOBwO6YG3Wq1YLBasVqsc0wGKz92VbGs9X4UQOJ1OOjo6cLlcMm0Zthx+yWSSZDLJ6uoqoVAIRVFwu93EYjE2NjZIJBIYjUYymQxtbW0ytLBUKmE2m+X/0ul06PX6usnriZ1DiqIojyqxX+uueXq9nv7+fjo6Onjttdf4zd/8TbxeL+3t7dJ7XiqVeP/997lw4QLT09PMz89TKBQea7WiFshVs1i6u7vlnS4ejzMxMcHCwsKBy1Pfb7mqHla1ulF7e7s0gbjdbgYGBojH43R1dSGEIBaLPdJzvley2SyhUEhuF+99jgc+HzQeJdtaz1edTofX66Wnpwe3273jmmazWd59912mpqa4dOkS4+PjzM3Ncf36dUqlEvF4XD4nEgnK5TLxeJwTJ05w6tQphBDYbLYnHeJj8biKc00I0a0oSlgI0Q1Eajmoh6GuTjweD93d3QwNDXH06FGZ9qhmiuTzeRYXF7l+/TqRSIR0Ov3YwbGqDcVsNmOz2bDb7XJVq2avHKDKSHWTq3pdVfuUWoQDtmI71apHTqeTzc1NEolETRVnsViUBY23y2439QtalIbMWUBmfN1fwapcLhMOh5mdnZUOu1QqteMYnU4n/QjJZJLl5WUCgYD0VVSr1YaEAj6u4vwx8B3gL+49/6hmI3oIajaQ0+nktdde48SJExw+fHhHhaNsNssvfvELlpaW+Pjjj5mbm3viUCGr1Yrf76erqwufz4fX65U57ouLi4yPjxOLxVrVQXQ/dZOrWlFfnRTbEwtUb2tfXx+vvPIKS0tLvPvuu2QymZqdP5FIcOPGDZll9BRQ9zkLW6aRlZUV7t69i8vlAn4do2mz2XjjjTd49tln+eyzz7h79y7lcnnHDVJdsVqtVjweD+3t7QSDQTo7O7HZbHIRU292E470t2wZlTuEECHg37N18f+nEOJfAgvA7+3nIGFLcXZ0dODz+Xj++ef58pe/jM1mk9s72PLGXrlyhRs3bnDz5k2Wl5ef+LxqhXFVaappe+l0mpWVFWZnZ8lmsy2nOBstVzWcSC0ivV1xqkkL3d3dnD17Fr/fzyeffEIoFKrZ+VOpFFNTU5jN5pquZJuBRst2O9VqlVgsxsLCAiMjIztW9DabjRdffJFqtUpPTw8DAwMyNlrtAaaa5tra2nC5XHg8Hmw2G16vVy6YGtGBYTde9bcf8tY/q/FYHohqY2xvb+f8+fP09PQQDAZ3hIuogdGrq6tMT0+ztLREOp2uyfnVnjZqNXg1CyUajZJMJsnlcjWJCa03jZbr9hWn2vTu/p2BmgK7n9d3+/9V02tVh9/jhK01A42W7Xaq1SrhcBhFUThx4oRMOLg/S6i9vZ2hoSFKpdKOHYBer6ejowO73Y7VasVutzdFNbKmzxwyGo04HA76+vr49re/zdjYGC6XC5vNJi/e2toaP/nJTwiFQnz00UeEQqGa2RzVc/f09GAymWS+tKqo0+l0y602mwF1tVksFslkMmQymc9dx0qlQjablaX/9ns8yWRS5rzncjkKhUJLKs5molwuMz4+zuTkJGfOnHmoTVKdY/Drm9l2J939hcbv71Bbb5pecTqdTgYGBhgYGKCtrQ2HwyGDXNUJt7q6yvLyMuFwuGbbZlVINptN9rlR7Sm5XI5UKkU+nz8oTqGGoVa+eVhFInVLX4/JoToW1dWm1oSvNqh1BtbX15mbm5OVkdR6tmoo2naFul0xbncCbT9m+3cil8uRSCQeO057rzS94jx69Ch//Md/TCAQoK+vD7vdLi/q7OwsV65cYXJyknfffVfmINeC7Wl4r7zyimwEVq1WWVtbY2Zmpq5FBZ5W1NqN+701U00w6+vrO2qyaivO2nH16lX+43/8jwSDQV566SU8Ho+c0w9DjcnO5XI4HA5Z5OP+YxYXF7l8+TIbGxt1ueE1reJU61yqdTDb29uxWq2yXmK1WiWVShEKhVheXiYajdbMrqme32KxyOBdj8cjQyOy2aycXNrE2l/2KzxIraWqtlBRFEXaW9UVkibb2qK2aS6Xy4yMjFAul3G5XJ+zd96/lc9ms+RyuR2OYECGHxYKhR1lBZ/aFacQgsOHDzMyMsILL7xAX18fDodjR/xkoVBgYmJCrjRr6RkVQsjc91OnTuH3+zGbzbJ8lZqut7q6WrNzanweteCtmslTS1wuF6OjowwMDGA2m2v6vzUeTCQSoVAoMD8/z8zMDDabjUAggMPhkMeoCxW1ILlaAtBoNDIyMkJbW9uOmgaXLl1ieXmZGzduEI/H6+bQa0rFqdPp6Orq4ujRowwODu4oRqwoCoVCgUwmQzgc5u7du+RyuZpm7uh0Onw+H4cPH6a3txeXy4UQgmQySSqVIhKJsLKyIsMmNPYHNaJiP7yoanxue3v7I1sLa9QONX1Wp9MxPz+P0Wiks7NzR855R0cH/f39GI1G2bWhs7MTl8tFZ2enDFOCrSSG6elpJicnCYVCNY3z/SKa6htjMpkYGhqSFdzPnTtHT0+PXGmqwbEXL15kcnKSa9euydCRWmA0Gunp6cHj8XDy5ElOnz5NX1+fbJexvLxMJBIhFouxubl54OL/mgU1Vz0ajXL58mVCoVDNCgurOehdXV0899xzBAIBbDabDNSenJzUanHuM+pcVhRFlmVUyWazpNNpma2n3uC6u7vlAiabzbK6usra2hqffvop4+PjrK2t1fUzNJXiNJvNPPvsswwNDfHKK69w/vx5aYdSQ1fS6TTvvfce77zzDuvr62Sz2Zp9yU0mE4cPHyYYDHLu3DnOnz+P3W5Hr9fL0lehUEimh2nsD5VKhUKhQCQS4Ze//CWhUIiNjdqUjlTbN/T09PDyyy/j9Xqx2+2Uy2UWFhb47LPPZL1Pjf1BVZz3ZwnBlplsbm5OetzVTMG+vj7ZnXRzc5O7d+/KDMHbt2/XPQKiqRSnXq+nra1N3l1UGwdshYqofUXi8TjpdLpmcXZ6vR6LxYLH42F4eJjh4WG6urqw2WzyrhiPx4lEIrLquMb+oa44i8Uim5ubD4zxfFzUUBg1A0VN76xUKiQSCdbW1rSbYgNR57OaaunxePB6vbjdbikrNXli+6PeN7qmUpxms5kjR45w9uxZAoGALHYKW9XAL126RCgUYmJigrW1tZrFUFosFnp6eujp6eG3fuu3OH36NFarFavVSiwWY35+npWVFa5fv87Kygrr6+s1Oa/Gg1FXnGr30Vq1QlCL6g4ODjI4OChbN6hN+ebm5rh27Zpmu24CbDYbx44do7u7m7GxMfr7+3eEpakr1nrF+N5PUylONeDc6XTuuLuoX+xIJCLbu9YqyF312rW1tdHR0UFbWxter1ceo/YsWl9fl/UBi8XiE59b4+Gok0GtsP+k2zAhBBaLRTYKCwaDO5xCm5ubMmJCbaui0Th0Oh1msxm/309PTw9Op3NHNf5KpUIul5PFrRtBUylONW7T7/fLOnuFQoFUKsXCwgLvv/8+U1NThMPhL/hPu0MtFTc4OMhv/MZvEAgEZI/tfD4vQyd+8YtfEA6HuXHjhrSrarQOqu3c7/fzta99jS996UuyU0AikeCXv/wly8vLzM7Osrm5qWWDNRC19m1vby/f/OY3GR0dpaura8cx6XRattGoVcLLXmkqxSmEkLX71DtMpVKRfWKWl5dZWlp6Ym+2GlRtNptlyf2BgQHpYVWL26ppXKFQiNXVVeLxuNY2tg7cn3p3f1GIvSCEkGEvfX19jI2Ncfz4cfl+oVBgaWmJxcVFksmkVnegwaiJJ263m+HhYQ4dOgT8OjVX3X2qnWsbVUC8KRXn9pL4aifJVCpFNpt9YBWdvaDX6+nt7cXj8XDkyBEZ4H7y5ElpIiiVSty8eZObN28yPj7Op59+KtO+NPaf7R7VQCAAbFXb3+0NU6/Xy//hdrvp6OjgpZdeYmxsjL6+PgAZC7y8vMzHH3/MzMwMkUjdavtqPAS/38/zzz/P8PCwTMVUSw5OT08zPj7O7Owst27dks37GsFu6nH2Av+NrR4lCvB9RVH+cr/ajer1+h0ByaVSiXQ6zebmJsVi8YnvMDqdjkAgQH9/P6+++ipf//rXsdlsuN1umVJZKpWYnJzkvffeY2FhgYmJiQO3Eqm3XPeCTqeTXQt9Pp/8DuxWcaqB83a7XcYAnjp1ihMnTshc51KpJHvdqEV0D0JRj2aW627o6Ojg7NmzBINBaa5T+0/Nzs7y/vvvs7KywtTUFJlMpmERLrtZcZaBf6soyjUhhBO4KoR4F/guW+1G/0II8T222o0+cdc8NRRF9aCZTCY8Hg8ejwer1SobNe121am2aLDb7bJD5ZkzZ+jt7WV0dBSbzYbRaJQKc2Zmho2NDcbHx1lYWGB9ff2g2rzqKteHUalUpHNGvSmqMvP5fHzpS19idXUVo9FIJBIhkUiQTqexWq2y26i6jbdYLBgMBtnDyOPxMDAwQEdHB93d3VgsFqrVquw3dP36dWZmZqRd84B40ptCrnvF7XbjcDjo7+9nZGQEn8+H2WymUqmwuLhINBrlzp07TE5OsrGx8dhtvmvFbgoZh4HwvZ/TQohxoId9aDeqBsaWSiWMRiN6vR673U5vby/pdBq3243dbperz91gMBiw2Wz09PTwrW99i76+Pk6ePEkwGJSVxlU76sbGBu+99x5TU1N88skn3LhxQ9aNPGjUU66PQm3A5XK55OpB3WoPDg7y3e9+l1gshtVq5e7du4yPj5PNZmlra2N0dBS9Xk+pVEIIQUdHB06nU/ai6ujo4OjRo1gsFmn+SSaTbG5ucuPGDf7H//gfMhPsIKw2oXnkuheEEHR1dTEwMMDp06d56aWXZPnIQqHA9evX+eyzz7hy5QoXL15siiIse7Jx3uvVfAq4xD60G61WqyQSCaLRKB6PB6fTKdt+2mw2+vr6KBaLxGIxmTG0vY7j9iKn6mSxWCy4XC66u7sJBoN0d3fjdruxWq2USiUymQybm5vS+bO4uMjKyspT5SjYb7k+imKxSDgcxmAwyK6WJpMJk8mEwWDA6XRSqVTo7++XNRldLhcdHR0MDAzI4HUhhMwC6u/vx+/34/V6ZXGYTCZDqVRiZWWFSCTCwsIC0WhUdk88iDRSrntBCIHVapWtacxms4zhrlar0h6tlvprhoXMrhWnEMIB/CPwp4qipO6rwFyTdqNqtZN0Os25c+c4ceKE7GceDAb5zne+QywW486dO6yurspeNdvGKHORR0ZG6Ovrw+l0yvAmteWGWsk9Go0SCoWYmZnhJz/5CdFolNnZWemIehqoh1wfxfr6Oj/+8Y/lVk0IIW9y6m7BbDbzzW9+k0KhINtbqLnM2z3uaok4i8Uim/gZjUby+Ty3bt1ibW2NCxcucO3aNaLRqGzrfBBrDjRarnscK93d3Rw9elTuBLdHVqhRNc1UkX9XilMIYWRLCP9dUZT/de/lmrcbrVQqxGIxlpeXd9TW1Ol0Unm63W6y2azsob59y64qToPBwNDQEENDQ7hcLvx+PyaTCZvNhk6nI5fLya356uoqoVCIyclJ4vE40Wj0qUmprJdcH0W5XCYajZLNZmWWkFowWt1t6PV6/P4HLpAeimpiUZt/ra2tEQqFmJ+fZ3p6Wu40mmUi1pJmkOtuUW9uajk5dZcJvw5BUjuRNir06EHsxqsugP8KjCuK8h+2vVXzdqOFQoHPPvuM5eVlRkdHOXPmjLywJpOJYDBIsVikvb1dtv29f9muxv253W6ZcaCm1SUSCfL5PJcvX5YTaGJigmQyyeLiIoVCoamEs5/UU667oVgscvHiRcLhMK+99hrt7e2ykPRe+2Zns1lZdvDixYvEYjGuXbtGJBJheXm5rnUb602zyfVRmEwmWTbyhRde4NVXX8Xlcu1oUZNIJJiYmOCTTz4hmUw2jcx2s+J8CfhD4KYQ4tN7r/079qHdaKlUkpVwtge3qtXgVS+qz+fb8/8uFAqycvvt27dlCMrt27ebRhh1pm5y3Q2VSoXZ2VlisRj9/f2k02kURcFut+9acapyVIuDrKys8PHHHxMOh7l586Z0AjWDjWwfaSq5Pgq9Xo/P56O7u5uhoSEZ7A7Iykm5XI7V1VXm5+cbN9AHsBuv+gXgYVVka9puVFEU2Y7iwoULVCoVfD4fAwMD0luqbrcfVNi2UqkQj8elHUxtc6EG0N+6dYuNjQ2ZrhWLxZ5WpVlXue4GtedPuVzm2rVrsopRX18fNptNVqtqb2/H7Xazubkpu1Gurq7KLXk+nycWi7G6ukokEuHWrVsyDvgAhRw9lGaT64NQ/RZer5fnnnuOQ4cO0dvbu+OYdDotb3rN2GmhqTKHVMVZKBT4v//3/3Lx4kUOHTrEy8wVOVQAACAASURBVC+/TE9PD21tbTKE6EGtFMrlsqxelMlkyOVyRKNRZmZmWFtb4/333ycej8sJdNAnUSuhNuVKp9NcvHiR8fFx2tvbOXz4MF6vlzNnzuD3+zl8+DBut5tMJsPc3BzxeJzLly+TSCRYXl4mmUyyvLzMwsLCDlOOJuvmwWAwSN/Dyy+/zJkzZ2TvIXVBlEwm+fDDD5mZmWFlZaXBI/48TaU4VRRFoVgsks1micViTE1NkUgksNlseDweuXW/H7XYcDqdlgo4kUgQDofZ2NioWetgjf1FDRPT6XQsLy+TSqUwm82EQiFisRjT09NsbGywtLREKpWSkRBqCl46nX5qbNWthhACu91OX18fwWBQJraotSnUTqOLi4uy5XczpjqLet6J9xLeoDp51LATtdjwFzXtUuO81BXl9mKnhUKh0fatq4qinG3kAPaDWoetqOX+1AwiNQVTTaU0GAxUKhVZck6VuWq/VOVdRzS57gJVniMjI/zzf/7PCQaDvPHGGwSDQTnfp6amuHDhAvPz8/zt3/4tKysrlEqlRiUoPFSuTbnihF+HIhSLRa0+4lPG9hueunJsVDEHjdqh3gzVPkJ+vx+LxbKjRoRajWxlZUXuHJuRplWcGhoaBwu1ZkRXVxfnzp0jEAjg8XhQFIXl5WUZBfG///f/JpFINHUJR01xamho1AV1q26z2fD7/TKssFqtyrbboVCI2dlZstlsU9cP0BSnhoZGXVA71WazWaLRKLAVc1soFPjwww+5ePEiCwsLzeCL+EI0xamhoVEXVJu1Glut1+tlXYgrV67wT//0T59Lo25WNMWpoaFRF9Tme2tra7z77rs4HA5yuRzFYpHZ2VlKpVLLhAs2bTjSAUULWzmYaHLdA2pbk+2Vre6vdNYktF44koaGxsGkUqm0fNnGeivOGJC599xqdPDk4+6vxUCaEE2uBxNNrg+hrlt1ACHElVbc1rTquOtFq16fVh13vWjV67Pf495boUMNDQ0NDU1xamhoaOyVRijO7zfgnLWgVcddL1r1+rTquOtFq16ffR133W2cGhoaGq2OtlXX0NDQ2COa4tTQ0NDYI3VTnEKIN4UQd4UQ00KI79XrvHtFCNErhPi5EOKOEOK2EOLf3Hu9TQjxrhBi6t6zt9FjbRZaQbaaXPeOJtdHnLceNk4hhB6YBL4ChIDLwNuKotzZ95PvkXs9p7sVRbkmhHACV4HfAb4LrCuK8hf3vkReRVH+rIFDbQpaRbaaXPeGJtdHU68V5/PAtKIos4qiFIG/A75Rp3PvCUVRwoqiXLv3cxoYB3rYGu9f3zvsr9kSjkaLyFaT657R5PoInkhx7mEp3wMsbfs9dO+1pkYIMQCcAi4BfkVRwvfeWgX8DRrWvrPHLVrLyfZplSsc7DlbT7k+tuK8t5T/T8BbwDPA20KIZ2o1sEYjhHAA/wj8qaIoqe3vKVv2jQMZx6XJ9WDKFQ62bOsuV7Up2l4fwAvAO9t+/3Pgzx917L3BP82P6ONe73o99iLXbcc3+ro2+tH0cn3MOdvo69rox0Pl+iTVkR60lD93/0FCiD8B/gQ4/gTnOigsNHoAu2CvctVoDbnCLmSryXUHD5XrvjuHFEX5vrJVpeR39/tcGvVDlavSgpVzNB6OJtfd8SSKcxno3fZ78N5rD0RRlJ8+wbk06see5KrRUmiyrRFPojgvA6NCiEEhhAn4NvDj2gxLo4Focj24aLKtEY9t41QUpSyE+NdsOX30wF8pinK7ZiPTaAiaXA8ummxrh9asrb5oTb0OJppcDyYPlatW5ENDQ0NjjxzYLpcWiwWz2YzRaMRqtQIghABQ49QoFosUCgX5N9VqlWKxSKVSoVKpUK1W6z9wDQ2NpufAKU4hBHq9nmPHjnH06FGGhoZ4/vnnMZlMO45TFIW7d+9y8+ZNqtUqiqKQz+cZHx9nfX2deDxOMpls0KfQ0NBoZg6k4tTpdPh8PkZGRjh27BivvfYaZrN5x3GKouByueQKU1EUMpkMsViMcrnM5uZmgz6Bxl5Qb5RCCKrVqrwJahxsdLotK6O6ixRC7NhRKooid4z78X04UIpTp9Ph8Xiw2WycPHmS119/HZ/Ph16vf+DFCwaDfOlLX5IXOpvNYrFYCIfDfPTRR2xsbFCtVqlUKg34NBqPwmw243Q68fv9vPXWW7jdbi5evMjc3BzxeJxoNNroIWrUGL1ej8FgwOl00t/fj9Vqpa2tDavVSiAQwO/3k81m2djYYGNjgytXrpBMJkkkEuRyuZqO5cApTqfTicfj4dChQ5w/f16+9yDF6ff78ft/XTQlm81SrVZZXl5mfn6eO3fuUC6XNcXZhJjNZjweD8PDw/zhH/4hgUAAnU4nb4KxWExbeR4w9Ho9JpMJj8fDkSNHcLvdDA0N4fV6efbZZzl8+DDxeJyFhQUWFxeJx+MsLS2Ry+U0xflFVCoVyuUyuVyOZDKJ0WjEZrPt6m8NBgOdnZ0YjUb6+/vp6+sjlUqxurqqOYqaDJ1Oh9lsxmQyYTAYMJvNHD58mGq1itFoZHV1lWKxSD6f1xRoCyOEwOFwYDKZGBgYYGRkhI6ODp555hkcDgednZ3YbDba2trQ6/XYbDY6OzsBOH/+PH19ffz85z8nkUjUdFwHSnEqikK5XKZQKJBIJFhdXcXtdmOxWKRN5FGYTCbGxsYolUrMzc0RjUbls6Y4mwuj0YjD4cBut2M2m7Hb7bz22ms8//zzWCwWxsfH2dzclDZsjdZDtV/7fD68Xi9vvfUW3/zmN6WJxmAwoNPppH1TCIHH48Hj8citezQaZXFxkcnJyZqO7UApToBSqUSxWCQcDnP37l08Hg/pdPqBilO92FarVdpC9Xo9AC6Xi66uLjY2NqTRWaO52O4Q0Ol0WCwWueowm83k83lNdi2Guh03Go14vV4sFguDg4N0dHTQ29uLx+PBbDZTrVYplUrk83nK5TLFYpFisYjL5cLn82EymbBardhsNgyG2qu5A6U4K5UKyWSSdDrNj370Iz766CO8Xi+9vb0PnEAGgwGDwcDhw4f5gz/4AzweD7A1CQcHB2U854cffljvj6LxGFgsFkwmE06nE7fbTblc1hRni+FwOOjq6sLv9/OVr3wFv9/PkSNH6O7uxmw2Y7PZyGazzMzMkMlkmJ2dJZlMsra2RiwW49y5c7z99tu72mE+CQdKcQKUy2UA1tbWSCQSeL1ecrncAy+kxWLBarXS0dHxue2c1WqVHnpt8jUfarjJdvulurVTva9qmJJG86MuYpxOJz6fj66uLoaGhggEAgwNDeH3+8lkMqRSKdLpNJFIhHQ6zeLiojTLxeNxhoeHqVarmuJ8XEqlkgwlymazn5tAQgiOHz/OsWPHGBwcxGg0NmikGo9DuVwmk8mwublJoVCgWCxKm5dGayGE4JlnnuHQoUMMDw9z7tw53G43AwMDWCwW8vk809PTXL58mY8++ojNzU0ikQiFQoFkMkm5XKatrQ2Px4PBYKjLzfLAKk41GLpUKpHJZB54zIkTJwgEAnR0dEjbpkZrUKlUpMJUQ8Y0GbYmOp2OQCDAiRMnOHr0KG+88QYWiwWDwUC1WmV6eppoNMrNmzf56U9/SiaTkTHW6t8/88wztLe31+3GeWAV5/3o9XoZ1tDf34/P5+OFF17g5MmTeDyeHStORVFYWVnhs88+Y2FhQfPKNiFut5uxsTGGh4ex2+3aarMFMRgMBAIBXC4Xp06d4ty5c3R1dWEymSgUCiwuLpJOp7lw4QKzs7PcvHmTVCpFsVjc6vtzL3zQ6XTy0ksv8dxzzzEyMiKdQQaDQcZ9dnZ2ks1ma5YR+IWKUwjxV8BvAhFFUY7de60N+HtgAJgHfk9RlI2ajGifMBgMeL1eXC4Xr7zyCkeOHOHYsWOcPn1ahjSoKIrCwsICly5dOrCKs9Xl2tbWxokTJ+jv78fpdGqmlm20imxNJhPDw8MEAgHOnz/Pq6++ik6nw2AwkM1mGR8fZ3V1lZ/85CdcvXqVXC5HNpuVf280Gunr66O7u5vXX3+dr3/96xiNRoxGI+VyWcb3tre3EwgEiEQiNVOcu7lF/wB4877Xvge8pyjKKPDevd+bEoPBgM1mo729XSrK0dFRGdqwXWmWSiXm5+e5ffs28/PzrK6ukkgkDmoA9Q9oYbnqdDoZtqI5gD7HD2hi2ZpMJjo7OwkEAoyNjXHs2DE6OjpQFIVUKsXU1BQTExPcvn2b27dvE4lEZNgRIEOVfD4fg4ODHDp0SIYgqeYaIQQmkwmz2Yzf72dgYACv11uz78oXrjgVRfnFvUbv2/kG8Oq9n/8a+AD4s5qMqIYIIbDZbPh8PoaGhvhX/+pfMTg4iM/nw+FwfG7SZTIZfvrTn3L37l0uX77M7du3KZVKB3LF2cpyha0bot1ux2azaVv0+2h22Xo8Hk6fPk1PTw9vv/02Y2NjGI1GCoUCU1NTvP/++ywvL/Puu+8SjUbJZrNyew5bIUtjY2P4/X6+/vWvc+jQIXp7e3fM5+2mubNnz0qlOTExUZP5/Lg2Tr+iKOF7P68C/ocdWI92o2pFpO1B0Hq9Hp1Oh9vtJhgMEgwG6e7uxu/343Q6d1RLUh0NanplKBRiY2ODbDZ7UFebD6Op5PpFqDLX2BW7ku1+ylW1ObpcLnp6eujp6ZFZQWoxjrW1NZaWlgiHw8RiMTY2Pm9NUFesXV1ddHZ20t7ejtVqfWDkjKob1OeafZYn/QeKoiiPKrGvKMr3ge/D/pXiVw3ADoeD06dP09HRgd1ux2q10tPTw9GjR3E6nfT19WG1Wj+XSZBIJLh16xbLy8tcvHiRO3fusLm5+VSnWTaDXDX2h0fJdj/lGggEGB4eZmxsjLfffhufz0cwGESn03H58mUuXLjA3Nwcn3zyCZlMhnQ6/cD/093dze/+7u/S09PDkSNHaGtre2C93VKpRDab5c6dO1y5coWFhYWazenHVZxrQohuRVHCQohuIFKT0TwGQggMBgMOhwOv18vAwADBYBCXy4Xdbqevr49Tp049Mu2qUCiwtrZGOBwmHA6ztrZWx0/QVDSNXL8IdbW5Pe1yO0/zTe8hNFy2DoeDQCBAf38/Y2NjtLW1IYSgXC4TDocZHx9ncXGRxcVFac98EDabjcHBQYLBIG1tbZ8r4qMoitxF5nI51tfXWVlZqWmhj8dVnD8GvgP8xb3nH9VsRHtAXX4PDg7yne98B7/fT19fn7RtqOl3X7REL5fLJJNJGUz7FNMUct0NXq+X48eP09nZicViAZAJD2pVpO12MY3GyVZ14h0/fpxvfetb0lyWz+f56KOPCIVCfPDBB9y6dYt0Ov2FN71isUg8Hsdms9HR0bHjvc3NTVmP9ec//znhcJirV6+ysLBAKpWq2fdhN+FIf8uWUblDCBEC/j1bF/9/CiH+JbAA/F5NRrNHVMUZDAb5F//iX9DT0/NY/6dcLpNOp0mn00+N4mxmue4Gl8vF6OgoXq9X2qvV2gJqwYenVXE2k2y3e7cPHTrE1772NYxGI3q9nlgsxq9+9Ss+++wzbt++zczMzK7kVSqVSCaTOJ1OSqXSjvdyuRzhcJipqSn+/u//nvn5eZldVkt241V/+yFv/bOajuQJqFar5PN58vk8JpNpz0Zgu93OoUOHcDgcXLt2Taby1br4aTPRCnLdC9VqlY2NDZnHnEgkyGQyT+WWvRllu730m6IoFAoFstks0WiUtbW1XTli9Xq9LCfY1taG1+uV8bubm5syNfOXv/yldPAWCoV9iYpp+cwh1QicSqVwuVy43e7PGYq/iPb2dl5++WUikQg3btygXC6zuLh4oBVnq7N9IsKW4lxaWiIUCjEzM0M4HKZcLj+VK85mY7t3W6/XU61W2dzcJJFIsLi4yPT09EPTorej1l1ta2uTge8WiwVFUdjY2GB1dZWPPvqI//Jf/gvpdJr19fV9+w60tOLc3itofn6eYrFIb28vDodDtvdVDcTqxRNCYDQaMRgMsl4fbAnFYrHIikla3nNroVZLUuWuNW1rDtQK7m63W8411UYZi8XIZrMPXBWqla7USv9qeqXqmVcLWAshqFQqbGxsEAqFWFtbI51Os7m5KZsw7gctrzgrlQqzs7P85//8n/H5fLz55psEg0EymQzZbJbl5WVu3bolbZd6vZ7u7m48Hg9jY2McP35clt43m824XC5ZLFWjdVCjK7Znj2g0HrXe7ejoKENDQwgh2NjY4KOPPpLxmplM5nMKTq/X4/F4sFgs9Pf3097ezpe//GW++tWv4nQ66e7uRq/XUy6XyefzXL16lXfffZeFhQWSySTFYnFfzTQtrThV1BXn5uYmoVAIg8FAKpUik8mwsLDA1NSUNCLr9XpyuRxerxe3201fXx+A7FlisViw2+173u5rNB7VBqYpzuZBCIHT6ZRhQ2r4kVpXs1qt7ggVVLfzamy2zWaTge6Dg4McOXJErkQrlQr5fJ5MJkM0GmVpaYl4PC5LSu4nB0JxqnGYiUSCH/7whzgcDsrlsuyPvr6+Li+kEIKVlRXMZjNra2tEIhGGh4f5jd/4DcxmM8eOHcPlcrG6usqdO3ca/Mk0dotOp8Pr9QLgdDq1/PUmY7s8LBYLPT09mEwmzp07R39/v3yvra2N3t5e7HY7vb29MmXa4XDIVSb82rP+f/7P/2Fubo5f/epXTE1Nkcvl6uIQPBCKc3s4USwW+8Ljt/fcVguflkol7HY73d3dGAwG3G73fg5Zo8aovaOq1aqM69RoDlSlqT6rRToABgcHcblc8tienh6OHz+Oy+VicHAQu90u7Zkq1WpVFrL+7LPPuHHjBlNTU3VNXDkQivNxSSaTzM7O0tnZSblcRqfT4XK5qFQqeDwe3G43xWJR8663CKqN02q1YrfbKRQKFAoFzUnUYAwGg6whAVsrzr6+Pnw+Hy6Xa0epOLfbTVdXF2azGafTKds/A9LRGwqFuHDhAmtra1y/fp1QKEQqlarvZ6rr2ZqM9fV1MpkMPT09UnGq5ffb29vxeDxkMhmtN3eLoCpOm82G0+lEr9c/tUHwzYIaAG+xWGTMpcPhYGRkBIBjx4498G+2P6vkcjni8Tg3btzgL//yL1lbWyOTyVAqleou46dacd6PGqpkNpuxWq1YrVZKpZIM2tVoblTHgtqs7f4C1Rr1p1qtEolEmJ2dpbu7m7W1NemA3Z6ooqbIqjGfaptnvV4vww5jsRgTExPMz8/LBU2jYnWfasWphrCoWwidTifbMLS3t+P3b1XeeoqLfrQM6mRTuyVaLBaKxWKjh/XUUyqVuHr1Knfu3CGfz+NyuWhvb+fw4cPSbqkoCuFwWPoejEYjNpuNkZERrFarTKW9ceMGP/zhD1lZWSEejzd0J9gSivP+pXutvGYWiwW32y3vfmpcaKVSoVQqSc+8RmuwvWVwuVx+KtMtmw01QaVYLBKJRFhaWiKXy2Gz2XaE/K2vr5NMJmWTNnWuq3+vbtPD4fC+ZgTtlqZXnGoPEp1OJ20k+Xz+c8n9j8PIyAgvvvgiR44cwWq1Ui6XCYVCJBIJ7t69y507dygWiweyAvxBQ1EU8vk82WyWjY0N2T5WU56NR12EXLlyhcXFRZlvrm7VhRCMjIzQ19fH4cOHefbZZ7FarZjNZrlinZ6e5he/+AW3b9+u2fx/ElpCcapBzRaLRYYOPe6F27569Xq9DA8PyxCkarUqc1zX19cfWH1aozlQ7V7bVx3qTkGNhGj05NLYQpVTNBrdEQoIv7ZLw5bTqFgs4nK5sFgsVKtVisUiq6urzMzMsLy8vCMmu5E0reJUswP6+/s5e/asLIKqKAo/+9nPuHPnzp4UqMFgwOVyYTKZ6OjowOFwcP78eV544QW8Xi8mk4lcLsf4+Dizs7OEw+Ev/qcaDSObzbK0tEShUKCvrw+LxYLNZsNoNNLZ2UlfXx/pdJp4PK7tGJoMvV6P1WrFYrEwPDxMW1sbL774IidPniQQCABbW/dPP/2UWCzGe++9x+3btwmHw03jpN1NPc5e4L+x1aNEAb6vKMpf7ne7UXWlGQwGeeWVV/D5fIyNjaEoCtPT08zOzgLsWnHq9XpZFX54eJjOzk5OnDjByZMnZZxYKpWS/Zt3E0jfyjRKrrUim80SiUTQ6XRysqmREG1tbXR3d2M0GkkkEk+V4mwFuaoec5fLxfHjx+nt7eWFF17g1KlT0oueSCS4fPkyCwsLfPzxx0xNTe1r0Y69spsVZxn4t4qiXBNCOIGrQoh3ge+y1W70L4QQ32Or3WjNuuapQcxqjqrX68Xj8VCpVBgaGuL48eOy0rPaaE1RFLnq6OjowOPxyCKqNptNpnIFAgGZp67T6WQmgmqAVusDHnAaItdakUwmmZiYIJPJyFqqKk95A7emlataS8Dv98veYGfOnMHv99PZ2YlOpyORSLC6usrKygp37txheXlZ3vyaRWnC7goZh4HwvZ/TQohxoId9bDcqhMDlcuH3+xkeHua5556TxuRiscjZs2ex2+3Mzs4yOTnJ+vo6k5OTVKtV2tracDqdPPfccxw/fhyHw0F7eztOp5PR0VHsdrsMxlWdTqVSiUwmQyKRYGFhgenpaZLJZC0+StPSCLnWktXVVX7+858zNjbGl7/85c+1UHhaO2A2s1zNZrNs7ftHf/RHsv/Q9jKQKysr/OxnPyMUCvH//t//IxqNyveaiT3ZOO/1aj4FXGKf242qRmOj0SiVHGzdtdrb2wkGg/IOFI/Hga0wpe7ubpxOp2zmZLPZ8Hq92Gw23G43VqtVOpvUklTpdJqlpSXZ0Cmfzz9t27sB6iTXWlEsFkmlUqRSKRn5oAW876RZ5KqW+lPraQ4MDNDZ2YnX65VO2bW1NWKxGFNTUywtLcldX7M6+HatOIUQDuAfgT9VFCW1/Qtaz3ajBoOBEydOMDY2JptyJZNJ5ubmqFardHZ2yvqaHo9nRziT2WzeMblSqZQU1j/8wz+wtrbG+Pg4yWTyqVGczSLXvZLJZFhaWsJut8uWGffHBj7NNItcdTodPp8Pt9vNyy+/zNe+9jU6OzsZGxtDr9ezsbFBJpPhH/7hH3jnnXdIpVKsrq5SLBYf2h64GdiV4hRCGNkSwn9XFOV/3Xt5X9uNqtW8S6UShUJBrjrV+n5Op1Mem06nMZlMVKtV2ZzeZrM9tBix6o1XFWc4HGZ2dpZoNPq0NWyru1xrhVqLsVgsUiqVms4G1kiaRa5quwyr1YrL5aKrq4uRkRHppFUUhWKxyObmJpFIhMXFRTKZDOvr600vy9141QXwX4FxRVH+w7a39q3dqKIoslXvzZs3+elPfyq94E6nU5bSV1Hr+wGymsrD+qiXSiUuXbrE3NwcMzMzjI+PE4/HZS2/WnfDa1YaIddaosb1WiwWzGYzRqPxqbRp3k+zyFWn02Gz2bBarRw5coShoSGeeeYZAoGA3Lrn83kikQiRSIT+/n6+8Y1vMDExwYcfftj06bK7WXG+BPwhcFMI8em91/4d+9xuNJfLUSwWCYVC3Lp1i2AwyMDAgJwk2zEajXg8nl3931KpxNzcnMyfvX79OsVi8YHl+w84DZFrrVDD1dRaA5p9U9IUctXpdDK2tquri4GBAbq6uqT5DLZ2Del0mmQyKU1r2Wy2JW6Au/GqXwAe9o3ct3ajqhctGo1y+fJllpaWcLlc0sDsdrtxu907FKba8bJcLrO2tkY0GqVUKpHNZsnn86yurrK5ucnVq1dZWlpidXVVVlh52miUXGuFampJp9Oy4ZeqSC0WCx6Ph3w+3xKTsJY0i1zNZjN9fX20t7dz4sQJnn32WYLB4I6bm8lkIhAIYLPZmJmZkenOrbCAadrMIbVT4fLyMuFwGJ/Ph8lkoquri6NHjxIIBOjr68Ptdu8oCKAWr7179y63b9+WVeE3Nja4cuUKiURCFh1Qz6HRehSLRYrFopRnLpfDarUCW6ab9vb2llm9HETUrKBgMMjzzz/P2bNnd7Rzhq2d4sDAAIVCgdnZWRYXF4nFYi0xJ5tWcW6nWq2Sz+dZWloim83KeK+lpSXm5uZ2VE1SHQaTk5PMz8+TzWZJJBKytYaaw6w5Ew4GhUKBhYUFmWWmrjRNJhNGo1HbvjcQ1TmkPiqVikw0URNX1tfXyWazTExMEAqF2NjYaIl52RKKE7Y855cuXdpR9EOtv7gdtaCA6m1VS42pBQO0ftsHi42NDX72s5/h9/s5c+YMfX19xGIxHA6H7Kqo0RzkcjnS6TSLi4u89957xGIxJicn2djYYGVlhUgk0jKlHFtGcVar1achDVJjj5RKJZld4vf7EUIQiUS0licNRp2valymGmqUSqVYWlqSrXzVlEp15dkqiHp+sRoRKN1kXFUU5WyjB1FrGilXg8Egm3o5nU5Z+T2fz5PP5+tVHUmT632onSzNZjN+vx+n0ym36vl8nlgsJlOd1bjqJlxpPlSuLbPi1NB4EOVyWdZN1VqcNA+lUolIZCvGfmlpqcGjqT2ay1FDQ0Njj2iKU0NDQ2OPaIpTQ0NDY49oilNDQ0Njj2iKU0NDQ2OP1NurHgMy955bjQ6efNz9tRhIE6LJ9WCiyfUh1DWOE0AIcaUVY95addz1olWvT6uOu1606vXZ73FrW3UNDQ2NPaIpTg0NDY090gjF+f0GnLMWtOq460WrXp9WHXe9aNXrs6/jrruNU0NDQ6PV0bbqGhoaGntEU5waGhoae6RuilMI8aYQ4q4QYloI8b16nXevCCF6hRA/F0LcEULcFkL8m3uvtwkh3hVCTN179jZ6rM1CK8hWk+ve0eT6iPPWw8YphNADk8BXgBBwGXhbUZQ7+37yPXKv53S3oijXhBBO4CrwO8B3gXVFUf7i3pfIqyjKnzVwqE1Bq8hWk+ve0OT6aOq14nwemFYUZVZRlCLwd8A36nTuPaEoSlhRlGv3fk4D40APW+P963uH/TVbgxgG1wAAHglJREFUwtFoEdlqct0zmlwfwRMpzj0s5XuA7dVMQ/dea2qEEAPAKeAS4FcUJXzvrVXA36Bh7Tt73KK1nGyfVrnCwZ6z9ZTrYyvOe0v5/wS8BTwDvC2EeKZWA2s0QggH8I/AnyqKktr+nrJl3ziQcVyaXA+mXOFgy7buclW7Qu71AbwAvLPt9z8H/vxRx94b/NP8iD7u9a7XYy9y3XZ8o69rox9NL9fHnLONvq6NfjxUrk9SHelBS/lz9x8khPgT4E+A409wroPCQqMHsAv2KleN1pAr7EK2mlx38FC57rtzSFGU7ytbVUp+d7/PpVE/VLkqLVg5R+PhaHLdHU+iOJeB3m2/B++99kAURfnpE5xLo37sSa4aLYUm2xrxJIrzMjAqhBgUQpiAbwM/rs2wNBqIJteDiybbGvHYNk5FUcpCiH/NltNHD/yVoii3azYyjYagyfXgosm2dtS1OpIQon4na06uHkTbUTPIVa/X09vbi8fjwWazYbPZ5HvlcplQKEQmkyGVSpHJZGp9ek2uB5OHyrXePYc0NPYFs9nMW2+9xQsvvEBvby+Dg4PodDqEECQSCf7u7/6OyclJPvvsMyYnJxs9XI0WR1Oc9yGEQAiBy+XCbrdTLpfJ5/NUKhWy2SzVarXRQ9S4D51Oh16vx+Px4Pf76e7uJhgMSsVpt9vx+/2sr6/vWIlqaDwumuLchhACs9mMyWTiW9/6Fm+++SahUIhPP/2UaDTKhQsXSCQSjR6mxjZ0Oh02mw2n04nD4cDhcGAymQDUQG6MRiOjo6NYLBZmZmYaOVyNA4KmOLchhMBoNGK1WhkdHeXll19mYmKCzc1NTCaTnJAazYNOp5OyUW96er1evq8oCjqdDrfbTT6fx2q1NnC0Ty/qTm7740Fsy1y6P5OpqdAU5zasVisvvfQSvb29HDlyBLvdjsVieaSgNRqL2WxmYGCAzs5O+vv76enp0bbjTYQQArfbjdVqpbe3l6GhIZxOJ4FAQN7wdDodhUKBYrFIMpkkGo2SyWRYWlpic3OTcDhMMpls9EfZgaY4t2GxWDh16hTHjh1jeHgYq9WKyWTSlGYTYzKZ6Onpoaenh0AgQGdnZ6OHpLENIQROpxO3283Ro0d55ZVX6Ozs5OTJk9hsNux2O3q9nnQ6TSaTIRwOc/fuXWKxGFeuXCEej5NOpzXF2YwIITAYDFgsFjo6Oujq6qJSqbCyssL8/Dy3bt1idXWVfD7f6KFq3IfVamVkZISBgQE8Hk+jh6NxH0II9Ho9BoOBtrY2+vv78Xq9OxYl201kbW1tDAwM0N7ejslkIplM4nQ6WVpaIh6PE41GKRaLZDKZhjpqNcXJVgyg1WrF6XQyMDDAoUOHiEaj3Llzh08++YR33nmHzc1NCoVCo4eqcR9Op5MvfelLHD58mO7u7kYPR+MBqIuSYDDImTNnMJlMGP9/e2f2G+d15unnq335ai/WQrK4SKIkRlEMw7IAaxI7TstOx56kGwmSTF9M0sj8AdPAXHTQN3M1QK4amdsE3bAHaMykgXasILGTdBwPZiYGZEm0otWiTIo7q1jFYrGKtS9nLsjvNCWTEhmZtZDnAQiSxSrWYb383jrn3X5W60MnOYfDgd1ux+PxMDAwQKvV4sKFC9RqNa5du8bs7CwTExNcvnyZ9fV15ubmlOPsNDabjXA4TCQSQdd1HA6HPDasrq5SLpepVqtdGaQ+qpjNZrlLMT62J4W202q1qFQqbGxsUKvV2rzSo40QglqtRrlcplarIYSg1WrRbDZ3TRgZJ0Cr1YrVaiUcDlOv10mn0ySTSVKpFMvLyzQajY5dk8pxAuFwmJdffplEIsHQ0BC6rjM9Pc2vf/1rHjx4IA2u6B5cLpes2fR4PDidTiyWnf+dG40G8/PzTE1Nsba21uaVHm1arRbJZJJMJsP8/DyZTAabzYbT6cRkMmG32zGZTFgsFsxms6ybNplMOJ1OWUo2MjLC4OAg4+Pj3Lhxg9nZWVqtFrVarSM7T+U42dxxRiIRIpEIdrsdTdPI5/Mkk0lyuZwqeu9CbDYbXq8Xr9eLzWbDYrF8KolnvNk1Gg3y+Ty5XE7tODtArVajVqtRKBTIZrM4HA7K5TJmsxmHw4HFYpE2rFarFItFTCYTzWYTs9mM3W7H5XJRqVRoNBqkUimsVqtscOgEynECbreb48eP09/fT6VSYWlpidnZWSYnJ1W3UJfS19fHhQsXGB4epq+vD7fb/akdZ71eZ2Njg5WVFW7dusUf//hHlpeXd/mNioPmypUr/PjHPwY238xMJhPBYBCHw4HL5cLpdJLP50mlUthsNgYHB/H5fFy4cIFjx45ht9sZHh5mYWEBl8uFzWbr2BuhcpxsdpZEIhFCoRD1ep1qtcrq6iorKyu0Wi11TO9CvF4vx44dY3Bw8KFuoe00Gg1KpRL5fJ7FxUVmZmYoFAodWK0CYHZ2lrW1Ner1utxVRqNRXC4Xuq7j8XjIZrPMzc3JJpRwOMzw8DD9/f243W5Z2rTbKaNdHArH6ff7OXHiBCaTiQcPHlAoFKjX6zSbzcc+zmq1YrfbCQQCRCIRPB4P169fJ5lMMjMzQ7PZVE6zy7BarVgsFqLRKGfPnqWvr2/XbqBisci9e/dYXFwkk8lQLBap1+ttXrHCwDgBtFot6vU6JpOJXC5HqVSiUCiQyWQol8uUSiV5DDeZTDgcDtxuNyaTiUqlQrVapdFoPPH6Pkie6Dg1TftH4N8DK0KIz2/dFgR+BowAM8B3hBAdi7qHQiFeeuklNE2TcRAhxBNfWLvdjs/nIxgMEo/HMZlMTExMcP36daanpw/1Eb0X7LoTRmJhYGCA5557Dq/Xu+t9C4UCN2/eZH5+nmQyeWR2m91qWyPWuZ1sNsvW+uRtQggZdrFYLLJUsFKpUC6X5TXeydPgXibAvwH8+SO3/RB4TwgxBry39X3bMRIE4XCYkZERRkdHiUQi+Hw+HA7HEx/v9/sZHR2VTrPValEsFikUCkchifAGXWrXnbBYLDLG9dxzzzE6OiprAXc7rpVKJWZmZpiZmaFcLrd5xR3lDXrItrB5LbvdbkKhECMjI4yNjTE+Ps74+LhsbEilUnz00UdMTk5SLpe7uxxJCPF/toTet/MXwJe3vn4T+N/A336G69oTfr+f/v5+zp49y1e/+lVMJhPT09OYTCYmJyef2KY1NjbG66+/ztDQEBaLhXw+z+rqKsvLywcx7Lar6Ga7PopRmuJ0OnnllVd4/fXXicVi2O32xz4unU7z29/+lsXFxSPlOHvJtgZ+v59AIMDg4CCf//znicVivPLKK/T19REIBAC4evUqb7zxBqlUipWVFSqVSvc6zl2ICiGM9GQSiO52x4OUGzU6EoyxYiaTCa/Xi8fjeewkI5PJhMlkwuPxEI/H5eScYrEoi90bjcZBLLnb6Qq7bnsOTCYTVquVUCiEz+ejv7+feDyO3++Xu00hxI67TiOW1qlavy5jT7ZtpzywpmkyydPX1yfnDQwMDBCJRAgGg3i9XsrlMvl8nqWlJRYXF8nlctTr9Y7mH546OSSEEI8bsS+E+AnwE/jsR/HbbDZ8Pp8cFGCxWIjH4xQKBWZnd5ZENoYOOBwOxsbGeOGFFygWi9y5c0caZm1traOB526gk3Y1sFqt+Hw+QqEQ3/3udzl58iTj4+MMDQ1htVoxm83SYe50ERllZjabjYWFBTY2Ng5imT3H42zbDrsa2Gw2Tp06RSgU4rXXXuNLX/qS7BgyYtmFQoG3336b69evc+/ePaanp/eU+D1o/lTHmdI0LS6EWNY0LQ6sfJaL2isWiwWXy4XD4ZC7SLfbjc/n2/UYZwwrdrvdcmL4ysoKmUyGZDJ51NvyusKuBmazWdrp9OnTPPPMM7Itdi+j/mw2G8FgkFKpxMrKitydHlG6yrawad9AIEAsFuP06dOcP39etmcaiZ9KpcLU1BRXrlwhnU6Tz+c7vWzgT3ecvwC+D/xo6/Olz2xF++DEiRO89tprJBIJ6Sj7+vqo1Wp4PJ4dH2OxWDhz5gzHjx/n5MmTWCwWSqUSH3/8sRT0OsJ0hV0NotEo3/jGNxgYGODUqVMPlR5td4C7OcNYLMa3vvUtkskkv/rVr5iZmWFlZeWotl12lW0BGS4ziuDh38JvRjulEarZXrfZDW9+eylH+p9sBpXDmqYtAP+VzRf/nzVN+0/ALPCdg1zkbiQSCV566SV59K7X6wSDQRqNBm63e8fHmM1mTpw4wfnz5xkeHsZisVAul3nw4AELCwuUSqU2/xWdoZvtamDMEBgcHGRkZESWHhkxzSc5z0gkwquvvko6nWZ2dhYhBNVq9dA7zl6wLSD1oLxer9z4GP3r2weBGBUVuw1x6QR7yar/1S4/+rPPeC17wpgo7XK5CIVCUlDNKHy/fPkyCwsLLC4u7vp4XdcJh8PS2ZbLZQqFAoVC4cgkhbrNrjth9CkbgyD2izHn0eVyMTIyQrPZJJvNsrCwQKvVOrQJo16wLWwWxM/OzlIul2VnkNfrJRKJSAE+t9vNs88+i8Ph4ObNm8Bmmdnq6mp3F8B3G2azmYGBAWKxGENDQwQCAVZWVrhy5QpLS0tcunSJ6enpXWMhJpOJcDjM0NCQLKotFoukUik5JFXRHZjNZqmR/qfsNsxms1S/PH/+PCMjIywvL3Pnzh0ajYaydYepVCpcvXoVq9Uqx8adOHGCCxcuyI2Rw+Hg61//Ol/72td45513EEKwvLxMPp9XjnOvGNv2SCTC6OgooVBIdgstLi7KjPjjEjzGCCur1Uqz2ZQj+yuViipb6RKMmJYxyMFqtT7V7zPK1JrNJrFYjMHBQfL5vJxFoOgcRgdQOp1mbm4Os9lMOBzG4/HQbDYf+h8IBoOMjo6iaRoff/wxzWazY0XwPeM4jZovXdf5yle+wsWLF4lEIgghSCaTvPvuuywtLbG0tLTrRCNj5p/FYpEF74Y8xurqKrlcruNlDgoIBoMMDAwwOjqK3+/H7XY/lfO0Wq0MDQ0Ri8W4ePEiwWCQ69ev884776ip/l1Aq9Xi7t27zM7O4vP5eO+994hGo7z66qtEo1FGRkYIh8OMjo7yve99j4mJCe7fv08qlWJtba0jNuwpx2m1WnE4HESjUQYHB7HZbFSrVQqFAul0mnQ6TaVS2dH5GcXU251nrVZjbW2NfD5PrVY7MvHNbsdut+P1eqXDNLKpj5YfPZogMoaybJ8obgyLcDgccgrW0NAQi4uLWCwW6vW62nV2AcViUX6USiU2NjaYn5+XiV4jkRSLxYhGowSDQarVKqVSSRbDt3Pn2TOO0+FwcPz4cSKRiOwcMeZm3rlzRx7Rd3N+FouFQCBAIBAgGo0SjUa5d+8e77//PjMzM0qIrYvQdZ3BwUGi0Si6ru8oi7HdkRpyDPPz82SzWZxOp3xcKBTCYrFIffV4PI7FYmFtbY1EIkEul2N1dVVNTeoSjKqHSqXCpUuXcDqd9PX1oes6L7zwAl/+8pfx+Xz84Ac/IJPJ8PbbbzM9PU0ul2vrEJeecZxWq5W+vj5isZjsFiqXy8zMzMjj+eOC/Ua/s67r6LouW7nu3btHKpVSu80uwuFw4Pf7ZZnKbpIY8G9TdVqtFtlslsXFRbxer+wuCQaDD93X7/djt9uJxWL4/X5arZZs4VN0nmazSblcplwuk81m0TRNxjmNDLuu63zxi19kdXWVa9euSV0w5Th3QNd1nn/+eUZHR4lGN9tsfT4fo6Oj2O12KpWKDPgXi0UymYxsnWw0GjidTsLhMNFoFKfTiRCCRqMh+9If3ebrui6dc6FQ6Iqi26NCtVplfX1dJvkajcZD7ZWwOaKsWq1SqVRklvUPf/gDU1NTBINBIpEIw8PDRCIRueMEZKzU5/MxODiIxWJheXlZnTi6FCGEDKckk0nu3LlDLBYjFArh8Xg4duwYtVqNer1OJpNp27p6xnF6PB5efPFFPve5z8ldRDAY5OTJkwwNDTE+Pk6xWOTGjRusrKxw8+ZNJicnZZ2my+Wiv7//oe4TQxjqUTE2o1Y0Go2SzWbZ2NhQjrONVKtVcrkc+XyearVKrVb7VAF0rVYjl8uxtrbGlStXZHfQ7du3ZQz83LlzvPjii7IZQgghlRNDoRDDw8OYzWbu3r3bqT9VsQeMk+TCwgIfffQRp06d4vnnn8fn8zE2NobdbmdpaYl79+61bU094ziNxI7FYpHF0MaQU+M2p9PJyMgIfr9fTlyp1+tUKhUcDgeJREIeAWGzM2V8fJx8Pk84HJYGMplM8l1tamqKxcVFlUBoI6VSiXQ6TTabpVwuU6/XpTiXQaVSIZ1Os7KywieffEIqlaJSqWC324lGo5w6dYpEIrHjMX+7RK2a8t875PN5Zmdn0XWddDqNy+UiGAzSarXw+/1YrVZp14OmZxynkVW32WzyAnI4HHJ8nDEUYGRkRI4Tq9frNBoN6vW6rAE1CqI1TePs2bPouk69Xn+ohEnTNLxeL7qu8+6773Lt2jUVA2sjqVRKJnlWV1dlRny7E8xms1Im9u233yaVSsmhLS+88ALf/va3ZSnTdowLq1arUSqVqFQq6k2xR5ifn5clSF/4wheIx+McO3aM8fFxrl27hq7rMtN+0PSM42w0GqyurpJMJmVv+k4Y5SeG5Giz2ZT6Jts1nFutFlarFY/HQ6PRwGq1PrTzcDqd2Gy2ruqPPSoYO8EnacsYJSiGvf1+v4xjG8qXj7ZqGjHvSqUimx+U4+wNjM3QxsYGhUJBSkN7PB4pFb2xsUG5XD7wU0TPOM5UKsVPf/pTAoHAro7TEHayWq1yGKpxcem6zpkzZ9B1XcY0s9msrP1cX1+XF6gQQhrgxo0bKuPehXi9XsbGxggGg/LEMD4+TiwWk5LB28M6BoY0yoMHD/jwww+lWJiid6hUKiwsLADIU+OpU6d46aWXmJ6e5vLlywd+QuwZx1kqlbh9+7Ysjt7Ncbrdbux2u3R8BoFAgOPHj+N0OmWbl3ERlUqlh4YXCyFIp9PkcjnS6bTakXQYI5u+PatuqJOazWbGxsaoVqucOXOGgYEBvF4vTqfzUwJgxnSkjY0NcrkcyWTyqI8R7EkajQb5fJ5CoUCr1ZKnjYGBAdbW1toiGbyXsXIJ4H+wOWpfAD8RQvz3dqvmNZtNcrkcFouFQqGw4xHaiIOazWZZz2cwPDzM2NgYZrOZubk5stkst27dYmJiQpa1GAghpIRGNps9lG2Y3WLXPaxzx9udTiexWIxgMCj7msPhMLquY7fbH3K2xptkpVLhgw8+4OrVq9y6detQxq17xa5PQy6X4/LlyywuLnLu3Dl0XZczLLxe7580SWu/7GXH2QD+ixBiQtM0D3BN07R/Bf6aTdW8H2ma9kM2VfMOTPzJGMixX4y2u9OnT/PNb34Tj8fDgwcPmJ2d5YMPPuB3v/vdUd1RdoVdH8fjdg4Oh0OWlcXj8R1jWtu7iwzt7omJCS5dukQ+nz+sIZiut+vTks/nuXXrFplMhuXlZQYGBjCbzQSDQakOcNA80TULIZaFEBNbXxeAu8AAm6p5b27d7U3gLw9qkU+DkQAyAshut5v19XVmZ2fJZrNHthSlF+xar9dZX1+nUCg8MUH0pN+TSqWYm5uT8gulUulQ2r4X7Pq02Gw2QqGQPGEYJYntZF/PtiU5+ixwmX0oInYSp9NJNBolHo8TjUYJhUKkUilu3LhBKpXq9PK6gm61a61WI51OyxbJ7XIohtN7nPMznGqtVuP+/fvMzMwwNTVFMpls+1CITtCtdn1anE4niUSCRCJBOBzG6/U+9ejB/bJnx6lpmg78C/A3Qoj8I4H3XVXz2ik3uhNmsxmHwyE7T0wmE61WS5a5HPaL50l0s13L5TILCwsIIUgkEthsNux2OzabbU/SGY1Gg2KxSC6XY2lpiYWFBdbX149EaKab7bpfjLJAQw2gr6+PsbEx4vG4jG+2u2xwT45T0zQrm0b4JyHEW1s370k1r51yoztht9sJBoMEAoG2b+e7nW6369LSEj/72c9kWdnJkycZGRmhv79/T49fW1tjYmKCpaUlfvnLX3L//n2y2exBLLWr6Ha77geTyURfXx8+n49EIsGxY8cYGhri4sWLsuHB4XC0/dp+YoxT23yr+gfgrhDi77f9yFDNgy5RzdsJi8WCrutSQngvsrJHgV6wa6VSYWlpifn5eZaXl0mn00+suTSGt5TLZTmoemlpieXlZVKp1KGv2ewFu+7E9nm5drtdTjLzer0EAgH6+vro7+9naGiI4eFhRkZGSCQSssnB6BZs10T4vbjpfwf8R+CmpmnXt277O7pQNW8ngsEgzzzzDMPDw3Iq0lE/nm/R9XY1jtpCCH7/+9/z8ccfY7PZOHHixI73L5fLNBoN7t+/z507d5ibm+P9999nbW2NhYWFoyKN0vV23Qm/34/H4yEcDjM8PIzX6+X48ePoui7j2z6fD7/fL0dDGgOuW62WHAAyOzvbHb3qQoj/B+y2Resq1bydcLvdDA4OEovFHgogH3Xn2Qt2NRI7rVaLyclJUqkUL7/8srTdo4OMjYEuCwsLTExMMDMzw4cffnikitx7wa6PomkaTqeTQCDAwMAAZ8+eJRwOc/78eYLBIKFQCF3XpfLlowghyOVyzM3NkclkumbH2dMYhdJ+v59isUij0SCTyZBOp9nY2Oj08hR7oNVqUSgUqNfr/OY3v2F1dfVT9zG6ghqNBnNzc0xNTZHNZg9lkXuvYYTI7HY7DocDt9stY5PxeBy32008Hqevrw+/3y+lguPxOE6nU4bZthe2G2+Uc3Nz5HI5JicnpQJAO04Vh95xulwuBgYG0HVdtlimUimWl5ef/GBFV9Bqtcjn8+Tzed566y1+/vOffypO/WiGffuHorMYTk/XdSld89xzzxEMBjl37pyUwwmHww/lIHbLRxgnjHK5zO3bt5mfn+fmzZtMT0+3TUPq0DvOdDrNhx9+KOObxqxHRW9yGNtfDzOapuHxeHA6nUQiEWKxmNT+8vv98sNms9FqtahWqxSLRTnVzBg+vf2IXqlUyGaz5PN5bt++zeLiIul0WsqltIND7zivX7/O9PT0Q/GwfD7f4VUpFEcDs9lMIpF4aHamoR9k5B8ikQjlcplcLsfKygpTU1OUy2VWV1dpNpsEAgFcLpf8nclkkitXrrC2tsbt27dZXV3dUcnhIDn0jrNSqSg9GYWigxhDxo245PZB4ysrK3IORblcJp1OMz8//5DjLBQKDw2kTqVSzM/Ps76+TiaT6chGSGtnDKgbCmo7zDUhxLlOL+KzRtlV2fUxv0NOrHK5XLhcLpksMpvNsl1y+/BqQ43BqKjYrvoAm7MHDGXSUql0kMNadrXrod9xKhSKziGEoFAotFW6tx0c/OA6hUKhOGQox6lQKBT7RDlOhUKh2CfKcSoUCsU+UY5ToVAo9km7s+oZoLj1udcI8/TrHv4sFtKFKLseTpRdd6GtdZwAmqZd7cWat15dd7vo1denV9fdLnr19TnodaujukKhUOwT5TgVCoVin3TCcf6kA8/5WdCr624Xvfr69Oq620Wvvj4Huu62xzgVCoWi11FHdYVCodgnbXOcmqb9uaZp9zRN+0TTtB+263n3i6ZpCU3T3tc07Y6mabc1TfvPW7cHNU37V03T7m99DnR6rd1CL9hW2XX/KLs+5nnbcVTXNM0MTAKvAAvAFeCvhBB3DvzJ98mW5nRcCDGhaZoHuAb8JfDXQFYI8aOtf6KAEOJvO7jUrqBXbKvsuj+UXR9Pu3ac54FPhBDTQoga8L+Av2jTc+8LIcSyEGJi6+sCcBcYYHO9b27d7U02jaPoEdsqu+4bZdfH0C7HOQDMb/t+Yeu2rkbTtBHgWeAyEBVCGApvSSDaoWV1Gz1nW2XXPaHs+hhUcmgXNE3TgX8B/kYI8dBsfrEZ31DlCD2IsuvhpN12bZfjXAQS274f3LqtK9E0zcqmEf5JCPHW1s2prXiKEVdZ6dT6uoyesa2y675Qdn0M7XKcV4AxTdNGNU2zAf8B+EWbnntfaJtymP8A3BVC/P22H/0C+P7W198HLrV7bV1KT9hW2XXfKLs+7nnbVQCvadprwI8BM/CPQoj/1pYn3ieapn0R+L/ATcBQtv87NuMm/wwMAbPAd4QQ2Y4sssvoBdsqu+4fZdfHPK/qHFIoFIr9oZJDCoVCsU+U41QoFIp9ohynQqFQ7BPlOBUKhWKfKMepUCgU+0Q5ToVCodgnynEqFArFPlGOU6FQKPbJ/wcGQZMznVL66AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cGeoygu_khy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NeuralNet(nn.Module):\n",
        "  def __init__(self,input_size,hidden_size,num_classes):\n",
        "    super(NeuralNet, self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.l1 = nn.Linear(input_size, hidden_size)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.l2 = nn.Linear(hidden_size, num_classes) #input size is hidden size, output is number of lcasses\n",
        "\n",
        "  def forward(self,x):\n",
        "    out = self.l1(x)\n",
        "    out = self.relu(out)\n",
        "    out = self.l2(out)\n",
        "    return out\n",
        "    #we dont apply softmax here, as we will use cross entropy, which will apply softmax for us\n",
        "\n",
        "model = NeuralNet(input_size, hidden_size, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqv2M_IuAeey",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loss and optimizer\n",
        "criterion  = nn.CrossEntropyLoss() #thats why we dont use it in forward\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learninig_rate)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4O-nQTSAkz3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "0c5ed22c-711e-4293-8965-64f0e9ff3384"
      },
      "source": [
        "# traininig loop\n",
        "n_total_steps = len(train_loader)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  for i, (images,labels) in enumerate(train_loader):\n",
        "    # We need to reshape images 100, 1, 28, 28\n",
        "    # We need to make 784\n",
        "    # 100, 784\n",
        "    images = images.reshape(-1,28*28)\n",
        "    labels = labels\n",
        "\n",
        "    # forward pass\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # backward pass\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    #lets print loss\n",
        "    if(i+1) % 100 == 0:\n",
        "      print(f'epoch {epoch+1} / {num_epochs}, step {i+1}/{n_total_steps}, loss = {loss.item():.4f}')\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1 / 2, step 100/600, loss = 0.5271\n",
            "epoch 1 / 2, step 200/600, loss = 0.2808\n",
            "epoch 1 / 2, step 300/600, loss = 0.1726\n",
            "epoch 1 / 2, step 400/600, loss = 0.1999\n",
            "epoch 1 / 2, step 500/600, loss = 0.2398\n",
            "epoch 1 / 2, step 600/600, loss = 0.1471\n",
            "epoch 2 / 2, step 100/600, loss = 0.1553\n",
            "epoch 2 / 2, step 200/600, loss = 0.1887\n",
            "epoch 2 / 2, step 300/600, loss = 0.2687\n",
            "epoch 2 / 2, step 400/600, loss = 0.1777\n",
            "epoch 2 / 2, step 500/600, loss = 0.1476\n",
            "epoch 2 / 2, step 600/600, loss = 0.1502\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRhi_nqLCA2n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0937ca02-380c-41c7-cd97-7b019f240016"
      },
      "source": [
        "# test\n",
        "with torch.no_grad():\n",
        "  n_correct = 0\n",
        "  n_samples = 0\n",
        "  for images, labels in test_loader:\n",
        "    images = images.reshape(-1,28*28)\n",
        "    labels = labels\n",
        "    outputs = model(images)\n",
        "\n",
        "    # max. will return values, and index - so we want index, as it's waht we need\n",
        "    _,predictions = torch.max(outputs,1)\n",
        "    n_samples += labels.shape[0]\n",
        "    n_correct += (predictions == labels).sum().item() #so each rorrect prediction will add one\n",
        " \n",
        "  accuracy = 100* n_correct / n_samples\n",
        "  print(f'Accuracy = {accuracy}')"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy = 95.24\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LurTCFowEimp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Next CNN"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}